{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지도학습 (Supervised Learning)\n",
    "\n",
    "## A. Introduction\n",
    "\n",
    "ML의 3범주 Supervised , Unsupervised, Reinforcement Learning의 범주 중 가장 많이 쓰는 것이 Supervised Learning(지도 학습)이다.\n",
    "\n",
    "궁극적으로 저희가 가장 잘 쓸 수 있는 테크닉은 어떤 문제가 있을 때, 그 문제를 어떻게 지도 학습(Supervised Learning) 패러다임으로 바꿔서 기존에 우리가 잘 알고있는 tranining 알고리즘으로 쓸 수 있느냐의 문제인 경우가 많다.\n",
    "\n",
    "물론, 이 강의에서는 비지도 학습, 강화 학습에 대해서도 언급할 예정이지만\n",
    "지도 학습의 측면에서 어떻게 접근하느냐에 대해서 더욱 포커스를 맞추자.\n",
    "\n",
    "#### Tradational Algorithm VS. ML\n",
    "\n",
    "- Tradational Algorithm <br>\n",
    "알고리즘을 정의하자면 여러가지 Definition이 있겠지만 가장 간단하게 정의해보면, instruction set을 어떻게 sequence로 나열해서, 그 나열된 sequence대로 instruction set이 실행되었을 때 결과가 우리가 원하는 대로 나올 것이냐의 문제라고 생각할 수 있다.\n",
    "\n",
    "\n",
    "- 머신 러닝: Data-Driven의 알고리즘으로 생각 가능<br>\n",
    "문제를 명세할 수 잇겠지만, 명세하기 어려운 문제들이 많다. <br>\n",
    "ex) face detection:  어떤 것들을 얼굴이라고 고려할 것이며, 옆으로 돌아간 얼굴에 대해서도, 고개를 숙인 모습이나, 등 뒤로 돌아서있는 모습에 대해서도 detection을 할 것인지에 대해서 명세하기 어렵다. <br>\n",
    "기존의 문제 해결처럼 명세를 통해서 알고리즘을 정의하기가 어렵다면, example을 통해서 해결하는 것이 머신 러닝이다. <br>\n",
    "머신 러닝은 input과 output의 pair를 정하여, 이러한 example을 가지고 알고리즘이라는 것을 거꾸로 찾아는 것이 머신 러닝에서의 접근 방법이다. 어찌보면, 기존의 알고리즘 접근 방법과는 반대의 방향에서 접근하는 것으로도 볼 수 있으며, 다른 말로는 알고리즘 디자인에 대한 meta-approach(메타한 접근)이라고 볼 수도 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## B. Basic Machine Learning: Supervised Learning\n",
    "\n",
    "#### 1. 지도 학습에 필요한 준비물\n",
    "\n",
    "1) Provieded (지도 학습을 위해 제공되어져야 하는 것 3가지) <br>\n",
    "- Training Set: a set of N input-output “training” examples  <br>\n",
    "$  D=\\left\\{(x_{1} ,y_{1}),\\cdots,(x_{N} ,y_{N})\\right\\}  $ <br> \n",
    "- Loss Function: A per-example loss function⭑ <br>\n",
    "$ L(M(x),y \\geq 0 $\n",
    "- Evaluation sets*: validation and test examples $ D_{val}, D_{test} $\n",
    "\n",
    "2) What we must decide (지도 학습을 위해 결정되어야 하는 것 2가지) <br>\n",
    "- Hypothesis Sets : $ \\left\\{ \\mathcal{H_{1}}, \\cdots,  \\mathcal{H_{M}} \\right\\} $ <br>\n",
    "각각의 Hypothesis set 내에는 모든 가능한 모델(All compatible models)들<br>\n",
    "ex) SVM, Kernel SVM, Nearest Neighbor ...<br>\n",
    "- Optimization Algorithm\n",
    "\n",
    "#### 2. 지도 학습의 진행 과정\n",
    "\n",
    "- Given: <br>\n",
    "Datasets: $ D_{train}, D_{val}, D_{test} $ <br>\n",
    "Loss Function: $ L(M(x),y \\geq 0 $ <br>\n",
    "Hypothesis Sets : $ \\left\\{ \\mathcal{H_{1}}, \\cdots,  \\mathcal{H_{M}} \\right\\} $ <br>\n",
    "Optimization algorithm\n",
    "\n",
    "#####  [Procedure]\n",
    "\n",
    "1) Training: 각 Hypothesis 마다, Training Set 을 사용해서 퍼포먼스가 제일 좋은 모델들을 찾자. <br>\n",
    "- $ \\hat{M_{m}} = argmin_{M \\in H_{m}}\\sum_{(x,y) \\in D_{train}} L(M(x), y) $ <br>\n",
    "\n",
    "\n",
    "2) Model Selection: Validation Set 을 사용해서 훈련된 모델들 중에 제일 좋은 모델을 선택. <br>\n",
    "- $ \\hat{M_{m}} = argmin_{M \\in H_{m}}\\sum_{(x,y) \\in D_{val}} L(M(x), y) $ <br>\n",
    "- keras tutorial이나, pytorch tutorial 같이 딥 러닝 튜토리얼들을 보면 하이퍼 파라미터 최적화가 굉장히 중요하다고 언급되어 있다. hyperparameter 최적화는 Model Selection의 단계이며 하이퍼 파라미터를 바꿀 때마다, Hypothesis set이 계속 나오는 것으로 생각가능하다.\n",
    "\n",
    "3) Reporting: Test Set 를 사용해서 제일 좋은 모델의 퍼포먼스를 측정 <br>\n",
    "- $ R(\\hat{M}) \\approx {{1}\\over{|D_{test}|}} \\sum_{(x,y) \\in D_{test}}  L(\\hat{M_{m}}(x), y) $ <br>\n",
    "- training set을 통해 최종적으로 reporting 하여 절반일 만큼 중요하다. (Valiation만으로 모델 셀렉하고 끝내면 F준다.) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 3가지 관점에서 보자 <br>\n",
    "• Three points to consider both in research and in practice <br>\n",
    "1. How do we decide/design a hypothesis set? <br>\n",
    "2. How do we decide a loss function? <br>\n",
    "3. How do we optimize the loss function? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: \n",
    "\n",
    "- https://www.edwith.org/deepnlp 조경현교수님, 딥러닝을 이용한 자연어 처리 강의 및 강의 자료 <br>\n",
    "- https://wikidocs.net/21758 (위 강의 강의록)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
