{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.  Introduction\n",
    "\n",
    "\n",
    "\n",
    "### 1.1 다항식 곡선(Polynomial Curve)\n",
    "\n",
    "- 각각의 ML 알고리즘을 해결하는 데는 서로 다른 방법과 기술이 필요하지만, 핵심에 속하는 중요 아이디어들은 서로 겹친다.\n",
    "\n",
    "- $y(x, \\mathbf{w}) = w_{0} + w_{1} x + w_{1} x^2 + \\cdots + w_{M}x^{M} = \\Sigma_{j=0}^{M} w_{j}x^{j} $\n",
    "    - 다항함수 $y(x, \\mathbf{w})$는 x에 대하여 비선형이지만, 계수 $\\mathbf{w}$에 대해 선형이다.\n",
    "    - 선형:\n",
    "        - superposition(가산성, additivity): f(x+y) = f(x) + f(y)\n",
    "        - homogeneity(동차성): f(ax) = af(x)\n",
    "    - ${E}(\\mathbf{w}) = {{1}\\over{2}} \\Sigma_{n=1}^{N} \\{ y(x_{n}, \\mathbf{w}) =t_{n}  \\}^{2} $\n",
    "    - 위의 MSE(식1.2)는 오차함수가 다항식의 형태를 지니고 있기 때문에 계수에 대해 미분하면, $\\mathbf{w}$에 대해 선형인 식이 나온다. \n",
    "\n",
    "\n",
    "- Root Mean Square Error\n",
    "    - $E_{RMS} = \\sqrt {2E({\\mathbf{w}^{*}}) /N }$\n",
    "    - N으로 나눔으로써 데이터 사이즈가 다른 경우에 비교 가능\n",
    "    - 제곱근을 취함으로써 표적값 t와 같은 크기를 갖도록 함\n",
    "\n",
    "\n",
    "- 10개의 데이터에서 9차 함수를 사용할 경우 \n",
    "    - 10차의 자유도를 가짐\n",
    "    - 낮은 차수의 다항식 집합은 더 높은 차수 다항식의 부분집합임\n",
    "    - 차수:9 다항식 집합은 차수:3인 다항식 집합이 만들어 낼 수 있는 모든 결과값을 전부 만들 수 있음\n",
    "    - 차수가 커짐에 따라 계수가 커지는 것 확인 가능\n",
    "    - 데이터가 늘어날 수록 이러한 과적합 문제 완화\n",
    "    - 모델의 복잡도에 관하여 더 자세하게는 매개변수의 수 이외에 여러 방법을 3장에서 배움\n",
    "\n",
    "\n",
    "- 최소제곱법 간략 (1.2.5)\n",
    "    - 최대 가능도 방법의 특별한 사례\n",
    "    - 과적합은 최대 가능도 방법의 성질\n",
    "    - 베이지안으로 회피 가능\n",
    "\n",
    "\n",
    "- 정규화(페널티항 추가) 5.5.1절에서 자세히\n",
    "    - $ {\\parallel}{\\mathbf{w}}{\\parallel}^2 \\equiv {\\mathbf{w}}^{T}{\\mathbf{w}} = w^{2}_{0} + w^{2}_{1} + w^{2}_{2} + ... + w^{2}_{M}   $\n",
    "    - 종종 w0는 정규화항에서 재외: 포함시키면, 타겟 변수의 원점을 무엇으로 선택하는가에 결과가 종속됨.\n",
    "    - 정규화항을 추가해도 closed form solution: 수축법으로 부름, 계수의 크기를 작게함\n",
    "    - 뉴럴넷에서는 weight decay로도 불림\n",
    "    - 오차함수에 $ {\\lambda \\over 2}  {\\parallel}{\\mathbf{w}}{\\parallel}^2  $를 추가\n",
    "        \n",
    "        - 이 때, 람다의 크기에 따라 과적합 정도를 통제\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 확률론\n",
    "\n",
    "- Pattern Recognition 에서 중요한 concept 중 하나는 바로 **불확실성(Uncertainty)**  <br> \n",
    "- 불확실성은 측정할 때의 노이즈를 통해서도 발생, 데이터 집합 수가 제한되어 있다는 한계점 때문에도 발생<br>\n",
    "- 확률론은 불확실성을 계량화하고 조작하기 위한 이론적인 토대를 마련, 패턴 인식의 중요한 기반.<br>\n",
    "- 1.5절의 의사결정이론과 확률론을 통해, 주어진 정보가 불확실하거나 완전하지 않은 제약 조건하에서 최적의 예측을 시행 가능\n",
    "\n",
    "\n",
    "- 합의 법칙, 곱의 법칙(결합확률 = 조건부 x 주변확률)\n",
    "- 결합확률\n",
    "- 주변확률\n",
    "- 조건부 확률\n",
    "- 베이즈 정리 \n",
    "    - $p(X,Y) = p(Y|X)p(X) $ (곱의 법칙)\n",
    "    - $p(Y|X) = {p(X|Y)p(Y) \\over p(X)}$ (곱의 법칙에서 대칭성 이용)\n",
    "    - $p(Y|X) = {p(X|Y)p(Y) \\over p(X)}$ (곱의 법칙에서 합의 법칙 이용)\n",
    "- 베이지안 정리는 사후 확률을 구할 수 있음\n",
    "    - 상자에서 나온 과일이 오렌지 였을 경우, 파란 상자에서 나왔을 확률\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "우리의 목표는 training set을 사용해 새로운 입력값 $\\hat{x}$이 주어졌을 때, Target Variable $\\hat{t}$를 예측하는 것이다. 우리가 앞으로 살펴볼 것처럼 기저에 있는 함수 $sin(2{\\pi}x)$를 찾아내는 것이 예측과정에 암시적으로 포함된다. 이는 한정된 데이터 집합으로부터 Generalization을 시행하는 과정이 필요하기 때무에 본질적으로 어려운 문제이다. 게다가 Observed data들은 Noise로 인해 변질되어 있어서 각각의 주어진 $\\hat{x}$에 대해 어떤 값이 적합한 $\\hat{t}$인지 불확실하다.\n",
    "\n",
    "확률론(1.2)에서는 이러한 불확실성을 정확하고 정량적으로 표현하는데 도움을 주고 \n",
    "의사결정이론(1.5)에서는 특정 기준에 따라 최적의 예측을 하는 데 확률적인 표현을 활용할 수 있게 해준다.\n",
    "\n",
    "- $sin(2{\\pi}x)$에서 random noise 섞은 데이터가 10 개일 때\n",
    "\n",
    "9차에서 오차 0 $\\to$ 당연, 해당 다항식은 $w_0$ ~ $w_9$까지 10차의 자유도를 갖고 있고 데이터도 10개이므로 but Overfitting\n",
    "\n",
    "데이터가 많으면, 복잡한(유연한) 모델을 활용한 피팅이 가능. 모델의 복잡도를 측정하는데 매개변수의 숫자만을 사용하는 것이 아닌 더 적합한 방법이 존재한다. (3장 선형회귀모델, Linear Regression Model)\n",
    "\n",
    "지금의 예시에서 사용한 최소제곱법(least squares approximation)은 최대 가능도(Maximum Liklihood 1.2.5)의 특별한 사례이다. Overfitting 문제는 Maximum Liklihood 방법의 성질 중 하나로써 이해가 가능하다. Bayesian 방법론을 채택하면 과적합 문제를 피할 수가 있다. Bayesian 관점에서는 데이터 포인트의 숫자보다 매개변수의 숫자가 훨씬 더 많은 모델을 사용해도 문제가 없다는 것을 앞으로 볼 것이다. Bayesian 모델에서는 데이터 집합의 크기에 따라서 적합한 매개변수의 수가 자동으로 정해진다.\n",
    "\n",
    "비교적 복잡하고 유연한 모델을 제한적인 숫자의 데이터 집합을 활용해 Fitting 할 때 자주 사용되는 기법이 Regularization 이다. Error Function에서 penalty항을 추가하는 것이다.\n",
    "\n",
    "$\\tilde{E}(w) = {1\\over 2}{\\Sigma \\{ y(x_{n},\\mathbf{w}) - t_{n} \\} ^{2} + {\\lambda \\over 2}  {\\parallel}{\\mathbf{w}}{\\parallel}^2  }$\n",
    "\n",
    "$ {\\parallel}{\\mathbf{w}}{\\parallel}^2 \\equiv {\\mathbf{w}}^{T}{\\mathbf{w}} = w^{2}_{0} + w^{2}_{1} + w^{2}_{2} + ... + w^{2}_{M}   $이고 계수  ${\\lambda}$ 가 정규화항의 제곱합 Error Function에 대한 상대적인 중요도를 결정짓는다. ${w_{0}}$을 포함하면 Target Variable의 원점을 무엇으로 선택택하느냐에 대해 결과가 종속되므로, 종종 ${w_{0}}$는 정규화항에서 제외한다. ${w_{0}}$만 따로 빼내어 별도의 정규화 계수와 함께 다른 항을 만들어 포함하기도 한다. (5장 5.1)\n",
    "\n",
    "$\\tilde{E}(w)$ 의 최솟값을 찾는 문제 역시 닫힌 형식이기 때문에 앞에서 미분을 통해 유일해를 찾아낼 수 있다. 통계학에서는 계수의 크기를 수축시키는 방법을 사용하여 수축법(Shrinkage Method)라고 하고, Quadratic(이차 형식) 정규화는 Ridge Regression이라고 부룬다. Neural Network의 맥락에서는 이를 Weight Decay(가중치 감쇠)라 한다.\n",
    "\n",
    "위에서 M = 9 일 때, Overfitting이 일어난 식에 $ln\\lambda = -18$ 을 적용하면 Overfitting을 피할 수 있다. 그러나 람다가 너무 크면 좋지 않다. 모델의 복잡도와 람다의 관계는 1.3 에서 자세히 본다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### 1.2 확률론\n",
    "\n",
    "Pattern Recognition 에서 중요한 concept 중 하나는 바로 **Uncertainty** 이다. <br> \n",
    "불확실성은 측정할 때의 노이즈를 통해서도 발생하고, 데이터 집합 수가 제한되어 있다는 한계점 때문에도 발생한다.<br>\n",
    "확률론은 불확실성을 계량화하고 조작하기 위한 이론적인 토대를 마련하며, 패턴 인식의 중요한 기반이다.<br>\n",
    "1.5절의 의사결정이론과 확률론을 통해, 주어진 정보가 불확실하거나 완전하지 않은 제약 조건하에서 최적의 예측을 시행할 수 있게 한다.\n",
    "\n",
    "\n",
    "* Sum Rule & Product Rule\n",
    "<br>\n",
    "Sum Rule : $p(X = x_{i}, Y = y_{i}) = {n_{ij} \\over N }$ 일 때, &nbsp; $p(X = x_{i}) = {\\sum_{j = 1}^L}p(X = x_{i}, Y = y_{i}) $ 이 때,  $p(X = x_{i})$를 Marginal probability(주변확률)라고 불린다.\n",
    "<br> \n",
    "Product Rule : $p(X = x_{i}, Y = y_{j}) = {n_{ij} \\over N} = {{n_{ij}\\over c_{i}} \\cdot {c_{i} \\over N} = p(Y = y_{j}|X=x_{i})p(X=x_{i}) }$\n",
    "\n",
    "* Bayes' Theorem\n",
    "<br>\n",
    "곱의 법칙과 대칭성 $p(X,Y) = p(Y,X)$ 로부터 베이즈 정리를 도출할 수 있다.<br>\n",
    "$p(Y|X) = {p(X|Y)p(Y) \\over p(X)}$\n",
    "\n",
    "ex) Red Basket에 오렌지 6개, 사과 2개 / Blue Basket에 오렌지 1개, 사과 3개 / $p(B = red)$ = 4/10 , $p(B = blue)$ = 6/10\n",
    "<br>\n",
    "어떤 과일이 선택되었는지를 알기 전에 어떤 박스를 선택했냐고 묻는다면 그 확률은 어떤 과일이 선택되었는지 관찰하기 '전'의 확률 == 사전확률(Prior Probability) p(B)라고 한다. \n",
    "<br>\n",
    "선택된 과일이 오렌지라는 것을 알게 된다면 Bayes' Theorem을 활용해 $p(B|F)$를 구할 수 있고 이는 사후확률(Posterior Probability) 이다.\n",
    "<br>\n",
    "예시에서 빨간색 상자를 고를 사전확률은 4/10 이므로 파란색 상자를 고를 확률이 더 높다. 그러나 선택된 과일이 오렌지라는 것을 확인하고 난 후 빨간색 상자를 고를 사후 확률이 2/3이므로 우리가 고른 상자가 빨간색 상자이었을 확률이 더 높게 된다. 따라서 고른 과일이 오렌지였다는 관측결과가 고른 상자가 빨간색일 가능성으르 높여주는 우리의 직관과 일치한다. 오렌지를 골랐다는 증거가 강력해 사전지식을 뒤엎고 빨간 상자를 골랐을 확률을 높게 만들어 주는 것이다.\n",
    "<br>\n",
    "$p(F|B) = p(F)$가 된다. 과일을 고를 확률은 어떤 상자를 골랐는 지와는 독립이다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.1 Probability density (확률밀도)\n",
    "\n",
    "연속적인 변수에서의 확률을 알아보자. 실수 변수 x가 $(x,x+\\delta x)$ 구간 안의 값을 갖고 그 변수의 확률이 $p(x)\\delta x (\\delta x \\to 0 일\\  경우) $로 주어진다면, p(x)를 x의 확률밀도(probability density)라고 부른다. 이때 x가 (a,b) 구간 사의 값을 가질 확률은 다음과 같이 주어진다.\n",
    "<br>\n",
    "$$p(x \\in (a,b)) = {\\int_{a}^{b} p(x)dx} $$\n",
    "<br>\n",
    "그리고  다음 두 조건을 만족해야한다. $p(x)\\ \\geqslant 0$ and $\\int_{-\\infty}^{\\infty}p(x)dx = 1 $\n",
    "\n",
    "확률 분포(probability distribution) 함수는 야코미안 인자로 인해서 비선형 변수 변환 시에는 일반적인 단순 함수와는 다른 방식으로 변화하게 된다. 예를들어, $x = g(y)$의 변수 변환을 고려해 보자. 그러면 함수 $f(x)$는 $\\tilde{f}(y) = f(g(y))$가 된다. x의 확률밀도함수(PDF) $p_{x}(x)$와 새로운 변수 y의 PDF $p_{y}(y)$를 살펴보면 둘이 다른 확률밀도를 가진 다는 것이 자명하다.<br>\n",
    "$(x,x+\\delta x)$범위에 속하는 관찰값(아주 작은 $\\delta x$에 대해)은 범위 $(y,y+\\delta y)$로 변환될 것이며, 이때 $p_{x}(x)\\delta x \\simeq\n",
    "p_{y}(y)\\delta y$다. 따라서 다음과 같다.\n",
    "$${p_{y}(y) = p_{x}(x) \\left|{dx \\over dy  }\\right| = p_{x}(g(y)) \\left|g^{\\prime}(y)\\right| }$$\n",
    "이로부터, 확률 밀도의 최댓값은 어떤 변수를 선택하는지에 따라 달라짐을 알 수 있다.\n",
    "x가 $(-\\infty,z)$ 범위에 속할 확률은 누적 분포 함수(CDF)로 표현된다.\n",
    "$$P(z) = \\int_{-\\infty}^{z} p(x)dx $$\n",
    "따라서, 확률 밀도는 누적분포함수의 미분으로 표현할 수 있다.\n",
    "만약 여러 개의 연속적인 변수가 주어지고 변수들이 벡터 x로 표현될 경우에도 적분을 전체 x 공간에 대해 시행한다.<br> 만약 x가 이산 변수일 경우 p(x)를 확률질량함수라고 부르기도 한다. 연속변수의 확률밀도와 이산변수와 연속변수가 조합된 경우의 확률 밀도에도 합의 법칙, 곱의 법칙, 베이지안 정리를 적용할 수 있다. ex) $p(x) = \\int p(x,y)dy \\ \\ \\ \\ \\ \\ \\ \\ \\ p(x,y) = p(y|x)p(x)$ <br>\n",
    "연속변수의 합과 곱의 법칙에 대해 정식으로 정의를 내리기 위해서는 **측도이론(measure theory)**에 대해 살펴봐야한다. 간략히 설명하면 측도이론에서 각각의 실수 변수를 폭 $\\Delta$인 범위들로 쪼개고 각각의 범위를 이산 확률 분포로 간주한다. 여기서 $lim \\Delta \\to 0$를 취하고 합을 적분으로 바꾸면 우리가 원하는 결과를 얻는다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.2 기댓값과 공분산 (Expectation & Covariance)\n",
    "\n",
    "확률과 관련된 가장 중요한 계산 중 하나는 함숫값들의 가중 평균을 구하는 것이다. 확률 밀도 p(x)하에서 어떤 함수 f(x)의 평균값은 f(x)의 기댓값(Expectation)이라 하며, $\\mathbb{E}[f]$라 적는다.\n",
    "$$ \\mathbb{E}[f] = \\sum_{x} p(x)f(x) \\qquad \\mathbb{E}[f] = \\int p(x)f(x)   $$\n",
    "각각 이산분포 연속분포일 경우 이다.\n",
    "<br>\n",
    "만약 유한한 N개의 포인트를 확률 분포 또는 확률 밀도에서 추출 했다면, 이산/연속 모든 경우에 각 포인트들의 유한한 합산으로 기댓값을 근사할 수 있다.\n",
    "$$ \\mathbb{E}[f]  \\simeq {1\\over N} \\sum_{n=1}^{N}f(x_{n})  $$\n",
    "**11장 표본추출방법론**에서 이 결과를 많이 활용한다.([1] week 10 Sampling Based Inference) 위 식에서 $lim N \\to \\infty$일 때 정확한 값이 된다.<br>\n",
    "다변수 함수의 기댓값을 구할 경우에는 어떤 변수에 대해 평균을 내는지 지정하여 계산할 수 있다. f(x,y)의 평균값을 x의 분포에 대해 구하라는 것은 $\\mathbb{E}_{x}[f(x,y)]$ 이다. 조건부 분포에 해당하는 조건부 기댓값(conditional expectation)은  $\\mathbb{E}_{x}[f(x|y)] = \\sum_{x}p(x|y)f(x)$이며, 연속변수에서도 마찬가지로 정의 가능하다.\n",
    "\n",
    "분산(Variance)은 다음과 같이 정의된다.\n",
    "$$var[f] = \\mathbb{E}[(f(x)- \\mathbb{E}[f(x)])^{2}]$$\n",
    "위 식을 전개하면 분산을 $f(x)$와 $f(x)^2$의 기댓값으로 표현가능하다. $var[f] = \\mathbb{E}[f(x)^{2}] - \\mathbb{E}[f(x)]^2$ <br>\n",
    "변수 x 그 자체로는 $var[x] = \\mathbb{E}[x^{2}] - \\mathbb{E}[x]^2$ 이다.\n",
    "\n",
    "두 개의 확률 변수 x와 y에 대한 공분산(covariance)는 다음과 같이 정의된다.\n",
    "$$var[x,y] = \\mathbb{E}_{x,y}[(x - \\mathbb{E}[x])(y - \\mathbb{E}[y])]  = \\mathbb{E}_{x,y}[xy] - \\mathbb{E}[x]\\mathbb{E}[y]$$\n",
    "공분산은 x값과 y값이 얼마나 함께 변동하는 가의 지표이며, 만약 x와 y가 서로 독립일 경우 공분산값은 0으로 간다.<br>\n",
    "두 확률 변수 x,y 가 벡터일 경우 공분산은 행렬이 된다.\n",
    "$$var[x,y] = \\mathbb{E}_{x,y}[(x - \\mathbb{E}[x])(y^{T} - \\mathbb{E}[y^{T}])]  = \\mathbb{E}_{x,y}[xy^{T}] - \\mathbb{E}[x]\\mathbb{E}[y^{T}]$$\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.3 베이지안 확률 (Bayesian Probability)\n",
    "\n",
    "Q. What is probability?<br>[1]\n",
    "$\\to$ a. ** Frequentistic view ** : It is the ** relative frequency ** with which outcom would be obtained if the process were repeated a large number of times under similar conditions. <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;b. Bayesian: It is your degree of belief in an outcome. \n",
    "\n",
    "'북극의 빙하가 이번 세기말까지 다 녹아 없어진다'는 사건을 생각 해보면 여러 번 반복할 수 없어 앞에서 본 과일 상자와 같은 방식으로 확률을 정의하는 것이 불가능하다. 그러나 우리는 이러한 사건들에 '북극의 얼음이 어러저러한 속도로 녹는다'와 같은 견해가 있으며 새로운 증거를 추가할 수 있다면 얼음이 녹는 속도에 대한 우리의 의견을 수정할 수 있다. 그리고 이러한 상황들에서 우리는 주어진 불확실성을 정량화할 수 있으며 새 증거가 주어질 때마다 불확실성을 수정해 최적의 선택을 내리게 해주는 일반적인 방법론이 확률의 베이지안 해석이다.\n",
    "\n",
    "불확실성을 나타내는 도구로써의 확률은 임의적으로 선택된 것이 아니다. 상식을 바탕으로 이성적으로 추론한다면 확률을 사용하는 것이 피할 수 없는 선택이라는 것을 알 수 있다. \n",
    "\n",
    "확률에 대한 개념을 일반적으로 확장하는 것은 패턴인식에서 큰 도움이된다. 1.1절의 다항식 곡선 피팅에서 관찰값 $t_{n}$에 대해서는 확률의 Frequentistic 관점이 적합해 보일 수 있다. 그러나 적합한 모델 매개변수 w를 정하는 데 있어 불확실성을 수치화하고 표현하려면 베이지안 관점을 사용하면 확률론의 다양한 장치들을 활용해 w와 같은 모델 매개변수의 불확실성을 설명할 수 있다. 더불어 베이지안 관점은 모델 그 자체를 선택하는데 있어서도 유용하다.\n",
    "\n",
    "가능도 함수(Likelihood function)는 Frequentistic, Bayesian 둘 다 중요하다. 머신러닝 문헌에서는 종종 음의 로그 가능도 함숫값을 error function으로 사용한다.\n",
    "\n",
    "[MLE MAP 설명 및 계산](https://github.com/NamSahng/Summary/blob/master/Intro2AI%26ML/W1%20MLE%20%26%20MAP.ipynb) [1]\n",
    "\n",
    "Frequentistic view로서 오차를 측정하는 방법 중 하나가 **부트스트랩(bootstrap)** 이다. Bootstrap 에서는 다음과 같은 방식으로 데이터 집합을 만든다. \n",
    "\n",
    "베이지안 관점의 장점 중 하나는 사전지식을 추론과정에 포한할 수 있다는 것이다. 합리적인 사전 확률을 사용하면 과도한 결론에 치우치지 않는다.\n",
    "\n",
    "사전 분포에 대해 의존도를 낮추기 위해 무정보적(noninformative) 사전 분포를 사용하는 경우도 있지만 이는 서로 다른 모델들을 비교하는 것을 어렵게 만든다. 그리고 실제로 좋지 않은 사전분포를 바탕으로 한 베이지안 방법은 부족한 결과물을 높은 확신으로 내놓기도 한다. Frequentistic 의 평가 방법인 **Cross Validation(교차검증법)**과 같은 테크닉을 모델 비교할 수 있다.\n",
    "\n",
    "베이지안 방법론은 지난 수년간 실용적 측면에서 중요도를 키워왔으며, Pattern Recognition and Machine Learning은  베이지안 관점에 큰 가중치를 두지만, 필요할 경우 Frequensic view의 concept에 대해서도 논의할 것이다. 베이지안 방법론의 토데는 18세기에 만들어졌지만 실제로 활용하는데 있어 전체 매개변수 공간에 대한 주변화(합산 또는 적분, Marginalization(?))와 같은 제약이 있었다. 예측치를 계산하거나 모델을 비교하는데 필요하기 때문이다. **Marcov Chain이나 Monte Carlo** (11장) 등의 표본 추출 방법이 개발되고, 컴퓨터 하드웨어의 발전으로 베이지안 테크닉을 실제로 사용할 수 있었다. 몬테카를로 방법론은 아주 유연하여, 다양한 범위의 모델에 적용할 수 있으나 연산량이 많아 작은 규모의 문제에서만 사용했었다. 최근에는 **Variational Inference(변분적 추론, 변분적 베이지안), Belief Propagation(기대 전파법)(10장)** 등의 효율적인 결정론적 근사 방법들이 개발 되었다. 이를 바탕으로 더 큰 규모의 문제들에 베이지안 테크닉을 적용할 수 있었다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.4 가우시안 분포(Gaussian distribution)\n",
    "\n",
    "정규분포(normal distribution)이라고도 불리며 단일 실수 변수 x에 대해서 가우시안 분포는 \n",
    "$$ \\mathcal{N}(x | \\mu , \\sigma ^{2} ) = {{1}\\over{(2 \\pi \\sigma ^{2})^{1/2}}}exp \\left\\{ {- {1 \\over {2 \\sigma ^{2}}}(x - \\mu)^{2}     } \\right\\}  $$\n",
    "\n",
    "평균 분산 표준편차는 위에 보이는 것이고, $\\beta = 1/\\sigma^{2}$는 정밀도(precision)이라 한다. \n",
    "\n",
    "다음은 연속 변수로 이루어진 D차원 벡터 x에 대한 가우시안 분포이다.\n",
    "$$ \\mathcal{N} (x | \\mu , \\Sigma ) = {{{1} \\over {2 \\pi ^{D/2}}} {{1} \\over {\\left\\vert \\Sigma \\right\\vert ^{1/2} }}}exp  \\left\\{  {-{1 \\over 2}(x - \\mu)^{T}\\Sigma ^{-1} (x - \\mu)  }  \\right\\} $$\n",
    "D차원 벡터 $\\mu$는 평균값, D X D 행렬 $\\Sigma$는 공분산이라 한다. 그리고 $\\left\\vert \\Sigma \\right\\vert $는 $\\Sigma$의 행렬식이다. 다변량 가우시안 분포에 대해서 간단히 보고 자세한 것은 2.3 절에서 보자.<br>\n",
    "관측된 데이터 $\\mathbf{x} = (x_{1}, ...x_{N})^T$를 살펴보면 관측된 N개의 스칼라 변수 $x$를 지칭한다. 여가서 벡터값을 갖는 변수의 한 관측값 $(x_{1}, ...x_{N})^T$과 구별하기 위해서 $\\mathbf{x}$를 사용했다. 평균값과 분산을 갖는 가우시안 분포에서 관측값들을 독립적으로 추출한다고 가정할 것이며 데이터 집합으로 부터 이 매개변수들을 결정하는 것이 우리의 목표이다. 같은 분포에서 독립적으로 추출된 데이터 포인트들을 **독립적이고 동일하게 분포(independent and identically distributed, i.i.d)**되었다고 한다. 두 독립사건의 결합확률은 주변확률의 곱이므로, 우리의 데이터 집합 $\\mathbf{x}$는 i.i.d 이기 때문에 $\\mu , \\sigma ^2$가 주어질 때 조건부 확률을 다음과 같이 적을 수 있다.\n",
    "$$ { p(x | \\mu , \\sigma ^{2} ) = {\\prod_{1}^{N}  \\mathcal{N}(x_{n}|\\mu , \\sigma ^{2} ) }  }$$\n",
    "위 식을 $\\mu, \\sigma ^{2}$의 함수로 보면 가우시안 분포의 가능도 함수에 해당한다.<br>\n",
    "관측된 데이터 집합을 바탕으로 확률 분포의 매개변수를 결정하는 표준적인 방법 중 하나는 MLE로 차즌 것이다. 주어진 데이터를 바탕으로 매개변수의 확률을 최대화하는 것이 주어진 매개변수를 바탕으로 데이터의 확률을 최대화하는 것보다 더 자연스럽게 느껴지므로 조금 이상하게 보일 수도 있다. 사실, 이 두 방법은 깊은 연관성을 갖는데 1.2.5의 곡선피팅 예시를 바탕으로 논의 해 볼것이다.\n",
    "<br>\n",
    "먼저 MLE로 알려지지 않은 가우시안 분포의 매개변수 $\\mu, \\sigma ^{2}$를 찾는 것을 계속해 보자. 로그를 취한 후 최댓값을 찾는 것은 동일하며, 곱셈의 언더플로우 문제를 방지가능하므로 이를 취하자.(30pg) 그리고 식의 $\\mu, \\sigma ^{2}$의 MLE의 해, 표본 평균(sample mean)과 표본 분산(smaple variance)의 값일 때이다.\n",
    "\n",
    "이 장의 뒷부분과 책의 나머지 부분에서는 MLE의 한계점에 대해 자세히 말할 것이다. 여기서는 우리가 현재 다루고 있는 단변량 가우시안 분포를 기준으로 MLE를 통해 계산한 매개변수 값이 어떤 문제를 갖고 있는지 간단히 보자. MLE는 구조적으로 분포의 분산을 과소평가하게 될 수 있다. 이를 **편향(Bias)**의 예시로, 다항식 곡선 피팅에서 살펴본 과적합(Overfitting)과 연관있다. <br>\n",
    "MLE의 해인 $\\mu_{ML}, \\sigma_{ML}^{2}$에서 평균적으로 $\\mu$의 추정은 올바르게 구할 수 있지만 분산은 (N-1)/N 만큼 과소평가하게 된다. 31pg 아래 그림에서 직관적으로 확인 가능하다. 그러나 데이터 개수인 N이 커질수록 문제가 되지 않으면 무한대로 가면 원 분포와 같아진다. 그러나 책 전반에 걸쳐 우리는 많은 매개변수를 포함한 복잡한 모델을 살펴봄에 따라 MLE와 관련된 편향(Bias) 문제는 더욱 심각해진다. MLE의 편향(Bias)문제는 우리가 앞서본 다항식 곡선의 피팅에서의 과적합 문제의 근본적인 원인에 해당한다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.5 곡선 피팅\n",
    "\n",
    "앞에서 다항식 곡선 피팅 문제를 오차 최소화의 측면에서 살펴보았지만 확률적 측면에서 살펴봄으로써 오차함수와 정규화에 대한 통찰을 얻을 수 있으며 완전한 베이지안 해결법을 도출하는 데 도움을 줄 수 있다.\n",
    "<br>\n",
    "곡선 피팅 문제의 목표는 N개의 입력값 $\\mathbf{x} = (x_{1}, ...x_{N})^T$과 해당 표적값 $\\mathbf{t} = (t_{1}, ...t_{N})^T$에서 새로운 입력변수 x가 주어졌을 때, 타겟 변수 t를 예측하는 것이다. 확률 분포를 이용해 타겟 변수 값에 대한 불확실성을 표현할 수 있으며 이를 위해 주어진 x값에 대한 t 값이 $y(x,\\mathbf{w})$를 평균으로 갖는 가우시안 분포를 갖는다고 가정할 것이다. 여기서, $y(x,\\mathbf{w})$는 앞의 식 $y(x,\\mathbf{w}) = \\sum_{j = 0}^{M}w_{j}x^{j}$에서 주어진 다항식 곡선이며 다음의 조건부 분포를 갖는다. \n",
    "$ p(t | x , \\mathbf{w}, \\beta) =  \\mathcal{N}(t, y(x,\\mathbf{w}), \\beta ^{-1}) \\ \\ \\ $ where $\\beta ^{-1} = \\sigma ^{2} \\qquad$  이 식을 도식화 한것이 32pg 아래 그림 \n",
    "<br>\n",
    "이제 training set {$\\mathbf{w, t}$}을 바탕으로 MLE를 통해 알려 지지 않은 매개변수 $\\mathbf{w}, \\beta$를  구해보자. 데이터가 위 식에서 독립적으로 추출되었다고 가정하면 우리의 가능도 함수는 다음과 같다.\n",
    "$${ p(\\mathbf{t} | x , \\mathbf{w}, \\beta) = {\\prod_{n=1}^{N} \\mathcal{N}(t_{n}, y(x,\\mathbf{w}), \\beta ^{-1}) }} \\qquad [f \\ 1.61] $$\n",
    "앞과 같이 로그를 취해 로그 가능도 함수를 만들면 \n",
    "${ p(\\mathbf{t} | x , \\mathbf{w}, \\beta) = - { \\beta \\over 2} \\sum_{n = 1}^{N}\\left\\{ {y(x_{n}, \\mathbf{w}) - t_{n} } \\right\\}^{2} + {N \\over 2}ln{\\beta} - {N \\over 2}ln(2 \\pi) }$ 가 된다.  $[f  1.62]$ <br>\n",
    "첫 번째로 다항식 계수의 최대 가능도 해를 구하자.($ \\mathbf{w}_{ML}$) $ \\mathbf{w}$ 에 대해 위 식이 최대로 만드는 값을 구하면 되므로 오른 쪽 두항을 제외 할 수 있으며 로그에 양의 상수를 곱해도 최대값의 위치는 변함이 없으므로 $\\beta / 2$를 1/2로 변환 가능하다. 마지막으로 로그 가능도를 최대화하는 대신에 로그 가능도의 음으로 두고 최소화를 하는 것은 같다. \n",
    "<br>\n",
    "결과적으로 $\\mathbf{w}$를 구하기 위해 MLE를 하는 것은 앞서 본(1.1절) Error function(오차함수) $E(\\mathbf{w}) = { 1 \\over 2} \\sum_{n = 1}^{N}\\left\\{ {y(x_{n}, \\mathbf{w}) - t_{n} } \\right\\}^{2} $ 과 같다는 것을 알 수 있다. 노이즈가 가우시안 분포를 가진다는 가정하에 MLE의 결과로 **제곱합 오차함수**를 유도할 수 있는 것이다. \n",
    "<br>\n",
    "마찬가지로 가우시안 조건부 분포의 정밀밀도 매개변수 $\\beta$를 결정하는 데도 MLE를 사용하면,  $ {1 \\over {\\beta_{ML}}} = {{1 \\over{N}}\\sum_{n=1}^{N}\\left\\{ {y(x_{n}, \\mathbf{w}_{ML}) - t_{n} } \\right\\}^{2}  }$ 이다.<br> 매개변수 벡터 $ \\mathbf{w}_{ML}$을 먼저 구해 이를 이용해 정밀도 ${\\beta_{ML}}$를 구할 수 있다.\n",
    "\n",
    "매개변수 $\\mathbf{w} , \\beta$를 이용해 새로운 변수 x에 대한 예측값을 구할 수 있다. 확률모델을 사용하므로, 전과 같이 하나의 점추정값이 아닌 t에 대한 **예측 분포(predictive distribution)**으로 표현될 것이다. 최대 가능도 매개변수들을 form 1.61에 대입하면 다음을 얻을 수 있다.\n",
    "\n",
    "$$ p(t|x,\\mathbf{w}_{ML}, \\beta_{ML}) =  \\mathcal{N}(t|y(x,\\mathbf{w}_{ML}), \\beta ^{-1}_{ML})  $$\n",
    "\n",
    "여기서 베이지안의 방식으로 나가기 위해 다항 계수 $\\mathbf{w}$에 대한 사전분포를 도입하고, 문제를 단순화를 위해 다음 형태를 지닌 가우시안 분포를 사용하자. \n",
    "<br>\n",
    "$$ p(\\mathbf{w}|\\alpha) = \\mathcal{N}(\\mathbf{w}|0 , \\alpha^{-1}\\mathbf{I}) = \\left( {{\\alpha} \\over {2\\pi}} \\right) ^{(M+1)/2}exp \\left\\{  {- {{\\alpha} \\over {2}} \\mathbf{w}^{T} \\mathbf{w} } \\right\\} \\qquad [f \\ 1.65]$$ \n",
    "\n",
    "여기서, $\\alpha$는 분포의 정밀도, M+1은 M차수 다항식 벡터 $\\mathbf{w}$의 원소의 개수이다. $\\alpha$와 같이 모델 매개변수의 분포를 제어하는 변수들을 **hyperparameter(초매개변수)**라고 한다. 베이지안 정리에 따라 Posterior는 likelihood와 prior의 곱에 비례하므로 \n",
    "$ p(\\mathbf{w} | \\mathbf{x} , \\mathbf{t}, \\alpha , \\beta) \\propto p(\\mathbf{t} | \\mathbf{x} , \\mathbf{w}, \\beta) \\ p(\\mathbf{w} | \\alpha)  $ 이며 이제 주어진 데이터에 대해 가장 높은 $\\mathbf{w}$를 찾는 방식으로 $\\mathbf{w}$를 결정할 수 있다. 다시 말해 사후분포를 최대화하는 방식으로 $\\mathbf{w}$를 결정할 수 있다는 것으로 이 방법이 **MAP(maximum posterior) 최대사후분포**이다. \n",
    "위식에 음의 로그를 취하고 f 1.62와 f 1.65를 결합하면 사후확률의 최댓값을 찾는 것은 다음과 같다.\n",
    "\n",
    "$$ { {\\beta} \\over{ 2}} \\sum_{n=1}^{N} \\left\\{  {y(x_{n}, \\mathbf{w}) - t_{n} } \\right\\}^{2}  + { {{\\alpha} \\over {2}} \\mathbf{w}^{T} \\mathbf{w} }  $$\n",
    "\n",
    "따라서 사후 분포를 최대화 하는 것이 정규화 매개변수가 $\\lambda = \\alpha / \\beta$로 주어진 식\n",
    "$\\tilde{E}(w) = {1\\over 2}{\\Sigma \\{ y(x_{n},\\mathbf{w}) - t_{n} \\} ^{2} + {\\lambda \\over 2}  {\\parallel}{\\mathbf{w}}{\\parallel}^2  }$\n",
    "의 정규화된 제곱합 오차 함수를 최소화 하는 것과 동일함을 확인할 수 있다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.6 베이지안 곡선 피팅\n",
    "\n",
    "비록 사전 분포 $p(\\mathbf{w}|\\alpha)$를 포함시키긴했지만 여전히 $\\mathbf{w}$에 대해 점 추정을 하고 있어 완벽한 베이지안 방법론을 구사하진 않는다. 완전한 베이지안적 접근을 위해 확률의 합의 법칙과 곱의 법칙을 일관적으로 적용해야한다. 이를 위해서 모든 $\\mathbf{w}$ 값에 대해 적분을 해야한다. 이러한 **'주변화'**(marginalization)가 패턴인식에서의 베이지안 방법론의 핵심이다.<br>\n",
    "곡선 피팅 문제의 목표는 training set $\\mathbf{x}, \\mathbf{t}$가 주어진 상황에서 새로운 변수 $x$에 대한 표적값 $t$를 예측하는 것이므로 예측분포 $p(t|x,\\mathbf{x},\\mathbf{t})$를 구해보자. 여기서 매개변수 $\\alpha, \\beta$는 고정되어 있으며, 미리 알려졌다고 가정한다.(이 후에 이러한 매개변수를 베이지안 적으로 데이터에서 유추하는 방법에 대해 논의할 것이다. EM?) <br>\n",
    "단순히 말하면 베이지안 방법은 단지 확률의 합과 곱의 법칙을 계속 적용하는 것으로 예측 분포를 다음과 같은 형태로 표현할 수 있다.\n",
    "$$p(t|x,\\mathbf{x},\\mathbf{t}) = \\int{p(t|x,\\mathbf{w})p(\\mathbf{w}|\\mathbf{x},\\mathbf{t})} \\ d\\mathbf{w} \\qquad f \\ 1.69 $$\n",
    "여기서 $p(t|x,\\mathbf{w})$은 위의 식  $ p(t | x , \\mathbf{w}, \\beta) =  \\mathcal{N}(t, y(x,\\mathbf{w}), \\beta ^{-1})$에서 주어진 것이다. 간략한 표기를 위해 $\\alpha$와 $\\beta$에 대한 종속성을 생략하고 적지 않았다. $p(t|x,\\mathbf{x},\\mathbf{t})$은 매개변수들에 대한 Posterior(사후분포)이며 f 1.66 의 오른쪽 변을 저규화함으로써 구할 수 있다. 3.3절에서는 곡선 피팅 예시와 같은 문제의 경우 사후 분포가 가우시안이며, 해석적으로 계산할 수 있다는 것에 대해 살펴볼 것이다. 이와 비슷하게 f 1.68을 적분하면 예측분포가 다음과 같이 가우시안 분포로 주어진다는 것을 알 수 있다. \n",
    "$$ p(t | x , \\mathbf{x}, \\mathbf{t}) =  \\mathcal{N}(t | m(x), s^{2}(x))  $$\n",
    "where mean:  ${ \\ \\ m(x) = \\beta \\phi(x)^{T}\\mathbf{S}\\sum_{n = 1}^{N}\\phi(x_{n})t_{n} \\ \\ }$ and variance: $ { \\ \\ s^{2}(x) = \\beta^{-1} + \\phi(x)^{T}\\mathbf{S}\\phi(x) \\ \\ } $ and matrix S: $ {\\ \\   \\mathbf{S}^{-1} = \\alpha \\mathbf{I} + \\beta \\sum_{n = 1}^{N}\\phi(x_{n})\\phi(x_{n})^{T}      \\ \\  }$\n",
    "<br>\n",
    "$\\mathbf{I}$는 단위 행렬이며 $\\phi(x)$는 각각의 원소가 $i = 0,....,M$에 대해 $\\phi_{i}(x) = x^{i}$인 벡터이다.\n",
    "\n",
    "\n",
    "이를 통해 식 1.69의 예측 분포의 평균과 분산이 x에 종속되어 있음을 알 수 있다. 타겟 변수의 노이즈로 인한 예측값 t의 불확실 성이 위의 분산에 관한 식의 첫 번째 항에 표현되어 있다! 이 불확실성은 식 1.64 $p(t|x,\\mathbf{w}_{ML}, \\beta_{ML}) =  \\mathcal{N}(t|y(x,\\mathbf{w}_{ML}), \\beta ^{-1}_{ML})$의 $\\beta_{ML}^{-1}$로 이미 표현되어있다. 하지만 분산의 식 두번째 항은 $\\mathbf{w}$의 불확실성으로 부터 기인한 것이며, 베이지안 접근법을 통해 구해진 것이다. 합성 사인 함수 회귀 문제에 대한 예측 분포는 35pg 아래 표현되어있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br><br>\n",
    "### Reference:\n",
    "\n",
    "Christopher M. Bishop, 패턴인식과 기계학습 Chapter 1\n",
    "<br>\n",
    "[1] 문일철 교수님, 인공지능 및 기계학습 개론Ⅰ Week 1,7, https://www.edwith.org/machinelearning1_17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
