# 빅데이터를 지탱하는 기술 1-3

## 머릿말

- 옮긴이 머리말
    
    빅데이터 기초지식, 빅데이터 기반 시스템의 구성, 검색, 수집, 파이프라인 - 배치처리, 스트림 처리, 자동화, 단계별 상황별 해설
    
- 책에 대하여
    - 책의 내용
        
        주제: 자동화된 데이터 처리, 데이터 처리를 어떻게 시스템화하는가
        
        폭넓은 지식 제공을 목표
        
    - 다루지 않는 내용
        
        BI: 기업의 업적 등을 수집해 경영상의 의사결정에 도움
        
        데이터 마이닝: 알고리즘을 사용해 데이터로부터 가치 있는 정보 발견
        
    - 대상 독자 예비지식
        
        빅데이터를 다루는 엔지니어, 작업 자동화를 하고싶은 데이터 과학자 대상
        

## 1장 빅데이터의 기초 지식

- 개요
    
    1.1 - 하둡, NoSQL DB등의 역할, 데이터 웨어하우스 중심 기술과의 차이
    
    1.2 - 데이터 파이프라인 시스템 구성 → 데이터 레이크와 데이터 마트
    
    1.3 - 대화형 데이터 처리, 데이터 프레임
    
    1.4 - 스프레드 시트, BI도구 - 장기적 데이터 변화 모니터링
    

## 1.1 빅데이터의 정착

cf. 분산 시스템: 네트워크에 연결된 여러 컴퓨터들의 처리 능력을 이용하여 메시지를 하나에서 다른 하나로 보냄(message passing)으로써 거대한 계산 문제를 해결하려는 분산처리 모델

- 분산 시스템에 의한 데이터 처리의 고속화
    
    빅데이터의 어려움 - 데이터 분석방법, 데이터 처리 방안의 수고
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled.png)
    
    - 빅데이터 기술의 요구
        
        인터넷 보급으로 세계 곳곳으로 액세스 되는 시스템이 증가함에 따라 RDB로는 취급할 수 없는 대량의 데이터가 쌓임 → 하둡과 NoSQL은 각각 다른 요구 충족을 위해 개발됨
        
    - 하둡: 다수의 컴퓨터에서 대량 데이터 처리
        
        방대한 데이터를 저장하고 순차적으로 처리할 수 있는 여러 컴퓨터를 관리하는 프레임워크
        
        구글의 분산처리 프레임워크 맵리듀스를 참고해 제작
        
        - cf. 맵리듀스:
            
            [https://www.slideshare.net/jayounglim/cloud-big-data](https://www.slideshare.net/jayounglim/cloud-big-data)
            
            [https://www.youtube.com/watch?v=7XIHdbKfQ4Q](https://www.youtube.com/watch?v=7XIHdbKfQ4Q)
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%201.png)
            
            분산시스템을 위와 같이 구성하고, 아래와 같이 데이터를 분산해서 저장했을 때, 네임노드나, 마스터가 한 꺼번에 처리하는 것이 아니라 각각의 데이터 노드에서 처리하고 그 결과를 네임노드에서는 취합만 하는 방식이 맵리듀스이다.
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%202.png)
            
        
        초기 하둡은 자바언어로 프로그래밍, SQL과 같은 쿼리언어를 하둡에 실행하기 위해 Hive 개발 (2009) → 사용자 확대
        
    - NoSQL DB: 빈번한 읽기/쓰기, 분산 처리의 강점
        
        전통적 RDB 제약 제거를 목표로한 DB의 총칭
        
        종류: KVS(Key Value Store), Document Store(JSON과 유사), Wide Column Store(여러 키를 통해 확장성 증가)
        
        NoSQL DB 제품은 각자 추구하는 목표가 달라 단순 비교는 어렵지만, RDB보다 고속의 읽기 쓰기가 가능하고 분산 처리에 뛰어난 특징이 있음
        
        모여진 데이터를 나중에 집계하는 하둡과 다르게, NoSQL은 애플리케이션에서 온라인으로 접속하는 DB 
        
        - cf. SQL vs NoSQL
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%203.png)
            
            클라우드 운영비용은 데이터 수와 쿼리의 수에 따라 차이의 크기가 달라짐
            
            - 확장
                
                ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%204.png)
                
                - 수직적 확장 (Sclae Up)
                    - CPU나 RAM 같은 부품이나 하드웨어를 추가해주거나 교체를 해 전체적인 성능을 향상
                    - 소프트웨어의 설계나 구조에 변화하지 않고 단순하게 데이터베이스 서버의 성능을 향상
                - 수평적 확장 (Scale Out)
                    - 더 많은 서버를 추가해서 데이터베이스를 전체적으로 분산하는 것
                    - 하나의 데이터베이스는 작동하지만 여러 호스트에서 작동
                
                SQL: 서로 다른 테이블끼리 연관되어 있어, 다른 PC나 서버에 배포하기 어려워 수평적 확장은 어려움 → 수직적 확장
                
                NoSQL: 서로 다른 컬랙션을 서버에 배포 가능하며, NoSQL에서 수평적확장을 대부분 지원 → 수평적확장
                
                ref) [https://velog.io/@rlcjf0014/Database-SQL-vs-NoSQL](https://velog.io/@rlcjf0014/Database-SQL-vs-NoSQL)
                
            - SQL, NoSQL 선택 시 고려할 점
                - 어떤 데이터 타입을 저장할 것인지
                - 얼마나 많은 사용자와 데이터를 저장할 것인지
                - 데이터의 관계는 서로 어떻게 되며, 관계를 고려해 쿼리를 할 빈도는 어떻게 될 것인지
            - 산업의 예시
                - SQL: Accounting Sowftware, 이커머스, CRM
                - NoSQL: 소셜 네트워크(Graph), 분산 캐시(Key-value), 컨텐트 관리 시스템(document), 실시간 데이터 분석(wide column)
                - Hybrid: 대부분 둘다 사용
                    
                    example
                    
                    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%205.png)
                    
    - 하둡과 NoSQL DB의 조합
        
        NoSQL DB에 기록하고 하둡으로 분산처리하는 흐름이 2011년 말까지 정착, 2012년에 널리 퍼짐. → 기존 기술에 비해 비용 저감
        
- 분산시스템의 비즈니스 이용 개척 - 데이터웨어하우스와 공전
    
    전통적으로도 데이터 웨어하우스를 많이 사용했고, 여러 방면에서 하둡보다 우수함. 하지만 데이터 웨어하우스는 안정적인 성능을 위해 하드웨어와 소프트웨어가 통합된 장비로 제공되었음. → 데이터 용량을 늘리기 위한 하드웨어 교체 및 확장의 어려움
    
    → 가속도적으로 늘어나는 데이터 처리 - 하둡 
    
        비교적 작고 중요한 데이터 - DW 로 사용 구분
    
- 직접 할 수 있는 데이터 분석 폭 확대 - 클라우드 서비스, 데이터 디스커버리지로 가속하는 빅데이터 활용
    - 클라우드 서비스 보급 - 구축 비용 감소 - 빅데이터 활용 증가
    - 데이터 디스커버리지 (BI 시각화 도구)
        
        정의: 대화형으로 데이터를 시각화해 가치 있는 정보를 찾으려고 하는 프로세스
        
    - 이전, 대규모 데이터 분석은 한정된 사람들 몫 → 현재, 누구나 사용할 수 있는 주변 기술

## 1.2 빅데이터 시대의 데이터 분석 기반

빅데이터 기술이 기존 DW와 다른 점: **다수의 분산 시스템을 조합해 확장성이 뛰어난 데이터 처리 구조를 만든다는 점** → 차이점을 알아보자

- 빅데이터 기술
    
    책에서 다루는 빅데이터 기술: 분산 시스템 활용해 데이터 순차적으로 가공하는 일련의 구조
    
    ex. 아래와 같이 여러 서브시스템 조합해 실현
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%206.png)
    
    - 데이터 파이프라인
        
        데이터 파이프라인은 어디에서 데이터를 수집해 무엇을 실현하고 싶은지에 따라 변화
        
        처음에는 간단한 구성으로 끝나지만, 목적이 추가됨에 따라 시스템이 복잡해지고 조합하기 어려움
        
    - 데이터 수집
        
        데이터의 생성은 여러 장소에서 발생, 여러 형태를 보임
        
        데이터 전송방법은 크게 벌크형과 스트리밍형으로 나뉨
        
        - 벌크형: 어딘가에 존재하는 데이터를 정리해 추출하는 방법. 정기적으로 데이터를 수집하는 데 사용
        - 스트리밍형: 모바일 앱, 임베디드 장비
    - 스트림 처리와 배치 처리 (3번동그라미)
        
        30분간 취합한 데이터를 집계해 그래프 → 시계열 데이터 베이스와 같은 실시간 처리를 지향한 데이터 베이스가 사용됨(그림 3번동그라미)
        
        이러한 스트림 처리는 현재 상태 결과를 빠르게 알 수 있지만, 장기적 데이터 분석에는 어려움
        
        장기적 데이터 분석을 위해서는 분산 스토리지와 분산 데이터 처리를 사용하는 것이 좋으며 이 때 배치처리를 통해 전송함(그림 4,5번 동그라미)
        
    - 분산 스토리지
        
        분산 스토리지란 여러 컴퓨터와 디스크로 구성된 스토리지 시스템을 말함. 
        
        데이터를 저장하는 방법
        
        Amazon S3: 객체 스토리지로 한 덩어리로 모인 데이터에 이름을 부여해 파일로 저장
        
        NoSQL DB: 성능 우수, 확장성이 높은 제품 고려됨
        
    - 분산 데이터 처리
        
        분산 데이터 처리란 분산스토리지에 저장된 데이터를 처리하는 프레임워크, 나중에 분석하기 쉽도록 데이터를 가공해 결과를 외부 DB에 저장하는 것이 주역할
        
        맵리듀스가 이부분에서 사용됨
        
        데이터 집계에 SQL이 가장 익숙함. SQL로 빅데이터 집계하는 2방법
        
        쿼리 엔진 도입: 분산 스토리지 상의 데이터를 SQL로 집계, Hive, 대화형 쿼리엔진 등
        
        데이터 웨어하우스 제품 사용: 분산 스토리지에 추출한 데이터를 데이터 웨어하우스에 적합한 형식으로 변환 → ETL 프로세스라고함
        
    - 워크플로 관리
        
        전체 데이터 파이프라인 동작 관리를 위해 워크플로 관리 기술 사용. 매일 정해진 시간에 배치 처리 스케줄 실행. 오류 발생한 경우 관리자에게 통지
        
- 데이터 웨어하우스와 데이터 마트
    
    기존 방식에서는 어떻게 데이터 웨어하우스를 구축했는가
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%207.png)
    
    데이터 웨어하우스: 웹서버, 업무시스템에서 이용되는 일반적인 RDB와 달리 대량의 데이터를 **장기 보존 하는 것에 최적화**. 정리된 데이터를 한번에 전송하는 것은 뛰어남. 소량의 데이터를 자주 읽고 쓰는 것에는 적합하지 않음.
    
    데이터 소스의 raw 데이터를 추출해 필요에 따라 가공하는 ETL 프로세스를 통해 저장됨
    
    데이터 웨어하우스 시스템에 과부하가 초래되면 안됨 → 필요한 데이터만 추출해 데이터 마트를 구축, BI 툴과 조합
    
    데이터 웨어하우스, 데이터 마트 모두 SQL로 데이터를 집계
    
    데이터 웨어하우스 중심으로 하는 파이프라인에서는 테이블 설계와 ETL 프로세스가 중요
    
- 데이터 레이크
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%208.png)
    
    빅데이터 시대가 되면 ETL 프로세스가 복잡해지고, 데이터들이 데이터 웨어하우스를 가정하고 만들어지지 않음.
    
    데이터 레이크: 모든 데이터를 원래 형태로 축적하는 장소. 데이터 웨어하우스에서 미가공의 원시데이터를 그대로 저장하는 점이 다름.
    
    데이터 레이크는 단순 스토리지이기 때문에 가공할 수 없음 → 맵리듀스, 분산 데이터 처리 기술 사용.
    
    필요 데이터를 가공 집계해 데이터 마트로 추출해 분석 수행.
    
- 데이터 분석 기반을 단계적으로 발전시키기
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%209.png)
    
    책에서 데이터 파이프라인의 자동화에 관해 설명함. 시작에는 애드혹 분석(일회성 데이터 분석)을 설명
    
    애드 혹 분석: 자동화가 아닌 일회성 데이터 분석. 데이터 마트를 만들지 않고 직접 연결하는 경우가 많음.
    
    정기적인 그래프와 보고서를 위해서는 대시보드 도구 사용.
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2010.png)
    
    복잡한 데이터 분석에서는 데이터 마트를 구축한 후 분석하거나 시각화함. 데이터 마트 구축은 배치처리로 자동화 되는 경우가 많아 워크플로 관리도구 사용. 
    
    워크플로 관리를 도입하는 단계에서는 데이터 분석보다 엔지니어링 작업이 많아짐. 장기적인 운용에는 안정된 워크플로 관리가 필수.
    
- 데이터를 수집하는 목적 - 검색, 가공, 시각화
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2011.png)
    
    아래 기능 중 어떤 것을 우선시 하는지에 따라 시스템 구성이 달라짐
    
    - 데이터 검색:
        
        언제 무엇이 필요할지도차 모르기 때문에, 시스템 로그 및 고객의 행동 이력 등 발생하는 모든 데이터를 취득. 검색은 신속하게 → 실시간 데이터 처리 또는 검색엔진 사용을 통해 키워드 찾는 기능 필요
        
    - 데이터 가공:
        
        ex. 웹사이트의 추천상품 제안, 센서의 비정상 상태 감지 → 데이터를 계획적으로 모아 데이터 파이프라인 설계
        
        자동화가 필수 → 워크플로 관리 도입해 테스트 반복 시행해 시스템 구축
        
    - 데이터 시각화:
        
        통계분석 소프트웨어, BI로 그래프를 만들고 앞의 상황을 예측해 의사결정에 도움을 줌. 시행착오의 연속. 시각화를 고속화 하려면 데이터 마트 필요
        
    
    cf. 기간계 시스템(Mission Critical System), 정보계 시스템(Information System)
    
    기간계: 비즈니스 근간에 관련된 중요한 시스템. 정지되면 업무가 멈춤.
    
    정보계: 사내 커뮤니케이션 관련. 기간계보다 유연한 운영 정책.
    
    데이터란 기간계 시스템과 정보계 시스템을 연결하는 것이다. 정보계 시스템은 데이터 복사하는 데서부터 시작. → 기간계 부하가 안걸리도록 해야함, 한 번 복사한 데이터는 지우지 않도록.
    
- 확증적 데이터 분석(Confirmatory Data Analysis)과 탐색적 데이터 분석(EDA)
    
    확증적: 통계학적 모델링에 의한 데이터 분석
    
    EDA만 책에서 다룸.
    

## 1.3 스크립트 언어에 의한 특별 분석과 데이터프레임

- NASA 로그 189만 로그, 스몰 데이터 파이썬 전처리 예시
    
    정규표현식 전처리
    
    시계열 데이터처리, set_index, resample(1d).size()
    
    SQLAlchemy 를 이용한 SQL 쿼리 (cf. SQLAlchemy는 ORM(객체관계매핑)일 종. ORM은 MySQL 워크밴치에서 스키마를 정의하지 않고, 코드를 통해 스키마를 정의해 관리할 수 있음)
    
    SQLlite를 이용해 csv 파일 불러오기 등의 예시
    

## 1.4 BI 도구와 모니터링

모니터링: 계획적으로 데이터의 변화를 추적해 나가는 것

- KPI의 예시
    
    KPI 모니터링에서 의식하고 싶은 것: 결과에 따라 다음 행동이 결정될지의 여부
    
    - 웹서비스
        
        DAU(Daily Active User): 서비스를 이용한 1일 유저 수
        
        Customer Retention: 서비스를 계속 이용하고 있는 유저 비율
        
        ARPPU(Average Revenue Pre Paid User): 유료고객 1인당 평균 매출
        
    - 온라인 광고
        
        CTR(Click Trough Rate): 광고 표시 횟수당 클릭 비율
        
        CPC(Cost Per Click): 1회 클릭에 대해 지불한 광고비
        
        CPA(Cost Per Acquisition): 1건 고객 취득을 위해 지불된 광고비
        
- BI도구 예시
    
    Tableau, Quick Sencse, MS Power BI, Google Data Studio
    
- 모니터링 기본전략과 BI도구
    
    모니터링 기본 전략: 정기적 보고 중요 데이터 변화 파악 → 원인을 알고 싶은 경우 데이터 재집계 및 살펴봄
    
    BI도구: 모니터링 기본 전략을 위한 소프트웨어, 탐색에 유용함. 데이터 디스커버리를 위한 BI도구인 경우, 시각화는 간단하게 수행 가능
    
    하지만, 제대로 설계된 데이터가 없으면, 생각에 딱 맞는 화면을 만들 수 없는 것이 BI도구의 한계
    
- 수작업과 자동화의 경계
    - 수작업: 별도의 DB인 경우, 일관성이 높은 경우(?), 주기가 긴 경우 (ex. 한달)
    - 자동화:
        
        자주 업데이트, 여러 명에게 공유되는 데이터, 중요성이 높은 데이터
        
        - 방안
            1. BI 도구에서 직접 데이터 소스 접속
                
                시스템 구성 간단, BI도구의 지원 데이터 소스 범위
                
            2. 데이터 마트 생성 → BI도구
                
                테이블 생성 자유로움, 데이터 마트 설치 운영 비용
                
            3. 웹 방식 BI 도구 도입 후 CSV 업로드
                
                자유로운 데이터 가공, 데이터 생성 업로드에 프로그래밍 필요
                
        
        책은 b 방식 위주로 설명
        

## 2장 빅데이터 탐색

## 2.1 크로스 집계의 기본

- 트랜잭션 테이블, 크로스 테이블, 피벗 테이블
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2012.png)
    
    - 크로스 테이블: 일반적인 테이블, 사람이 보기 편하지만 DB에서 열을 늘리는 것은 어려움
    - 트랜잭션 테이블: 행방향으로만 증가하는 테이블
    - 피벗 테이블 (크로스 집계, cross tabulation): 트랜젝션 → 크로스 변환하는 기능
- 룩업 테이블
    
    판매 이력에서 상품 ID를 key로 놓고 상품정보 테이블을 따로 사용할 때, 상품정보에 해당하는 테이블
    
    독립적 관리 가능
    
- 크로스집계 예시 - BI도구, pandas, SQL
    
    수백만이 넘으면 SQL 사용
    

## 2.2 열 지향 스토리지에 의한 고속화

- 3계층 데이터 집계 시스템
    
    데이터 레이크 → 데이터 마트 → 시각화
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2013.png)
    
    시스템 구성은 데이터 마트의 크기에 따라 결정됨
    
    시각화의 질, 정보손실 등 고려
    
    1) 일반 데이터 집계: 수분~수시간
    
    2) 시각화 시 크로스집계 수행: 수 초
    
- 데이터 마트 구성방안
    - 메모리: 모든 데이터를 메모리에, 수십 GB 내외에서는 지연이 크게 없음.
    - RDB: MySQL, PostgresSQL → 메모리 부족시 성능의 저하. 수억 레코드를 초과하는 데이터 집계에는 디바이스 I/O가 발생한다고 가정하고 어덯게 효율적으로 처리할 것인지 고민해야함
    - MPP(Massive Parallel Processing) - 데이터를 가능한 작게 압축하고, 여러 디스크에 분하고, 분산된 데이터를 읽기 위해 멀티코어를 활용해 디스크 I/O를 병렬 처리하는 아키텍처
        
        ex. Amazon Redshift , Google BigQuery
        
- 데이터베이스 구성방식: row oriented DB(행 지향 DB) vs column oriented DB(열 지향 DB, Columnar DBMS)
    - row-oriented  DB:  MySQL, Oracle 등 일반적인 RDB.
        
        ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2014.png)
        
        - 레코드 단위로 읽고 쓰기에 최적화. 일반적 업무 시스템에 사용.
        - 테이블의 각 행을 하나의 덩어리로 디스크에 저장. 매일 발생하는 대량의 트랜잭션을 지연없이 처리하기위해 데이터 추가를 효율적으로 할 수 있음.
        - 인덱스에 의해 검색되며, 인덱스는 적절해야 함.
        - 필요 없는 열까지 디스크로부터 로드됨
        - 보통 하나의 쿼리는 하나의 스레드에서 실행, 쿼리 분산처리는 가정하지 않음
    - column oriented DB
        
        ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2015.png)
        
        - 열별로 데이터가 저장되어 있기 때문에, 데이터 분석시 **필요한 열만을 로드** 하여 디스크 I/O를 줄임
        - 같은 열에는 유사한 데이터가 반복되기 때문에, **매우 작게 압축** 할 수 있음압축되지 않은 행 지향 DB와 비교하여 1/10 이하로 압축 가능
        - 데이터분석을 위한 집계는 고속이지만, 데이터를 저장하는데에는 시간이 걸림
        - 압축 데이터 전개, 대량 데이터 등으로 멀티코어를 활용해 고속화하는 것이 좋음
- MPP
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2016.png)
    
    - 하나의 쿼리를 다수의 작은 태스크로 분할하고 가능한 병렬처리
    - CPU 코어 수에 비례하게 고속화됨
    - 고르게 데이터가 분산되어야 병목현상이 발생하지 않음. 디스크와 CPU를 균형있게 늘려야 함.
    - MPP DB: 하드웨어와 소프트웨어 통합된 제품
    - MPP 아키텍처: 열 지향 스토리지로 구성한 하둡 + 대화형 쿼리 엔진으로 보통 구성 → MPP DB와 유사한 성능
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2017.png)
    

## 2.3 애드혹 분석과 시각화 도구

- 주피터 노트북 , matplotlib 설명
    - 수작업과 자동화에는 필요 지식과 도구가 전혀 다르다. 애드혹 분석 이 후, 자동화에 이유가 생기면 시작한다.
- 대시보드 도구
    - 정기적 쿼리 실행해 보고서를 만들 때에는 BI 도구를 사용한다.
    - 대시보드 도구: 그래프를 쉽게 추가하는 것이 중시. 최신의 집계결과를 즉시 확인 기대. 실시간, 하루 한번 자동 갱신 등
        - 오픈소스 대시보드 도구: Redash, Superset
            - Redash: 파이썬 기반 대시보드 도구. SQL에 의한 쿼리 실행 결과를 그대로 시각화 하는데 적합. 구조가 쉬우며 별도의 데이터 마트 구축이 필요 없음. 대량의 데이터 처리에는 어려움.
            - Superset: 파이썬 기반 웹 앱. 기본적 아이디어는 BI도구와 유사. 마우스로 그래프를 만들 수 잇음. 시계열 데이터에 대응한 열 지향 스토리지 Druid를 표준으로 지원 → 스트리밍 데이터 전송, 실시간 정보 취급 가능. RDB, MPP DB 등 조합 가능.
        - 실시간 시각화도구
            - Kibana: 자바스크립트 기반 대화식 시각화 도구. 실시간 대시보드, 엘라스틱 서치의 프론트 엔드로 개발됨. 엘라스틱 서치의 도입이 필수이며, 데이터를 엘라스틱 서치에 저장해야함.
    - BI 도구: 대화형 데이터 탐색이 중시. 장기적 데이터 추이 시각화, 집계의 조건 세부적으로 바꿀 수 있는 대시보드에 적합. Ex. Tableau
        - BI도구에 대화형으로 데이터를 참고하려면, 시각화에 필요한 정보만을 모은 데이터 마트가 필수
    
    ## 2.4 데이터 마트의 기본구조
    
    - OLAP(Online Anallytical Processing): 사용자가 다차원 정보에 직접 접근하여 대화 형태로 정보를 분석하고 의사결정에 활용하는 과정. 다차원 정보제공, 사용자 직접 데이터 접근, 대화형테 정보분석, 의사결정지원(질의, 목표탐색, 원인-결과 분석)
    - 다차원 모델과 OLAP 큐브
        
        RDB는 표형식으로 모델링 된 데이터를 SQL로 집계
        
        OLAP는 다차원모델의 데이터 구조(OLAP cube)를 MDX(Multidimensional Expression)등의 쿼리 언어로 크로스 집계하여 크로스 테이블을 구축.
        
        OLAP 고속화 예시: 크로스 집계의 조합을 미리 계산해 DB에 캐시해, 쿼리 실행시 집계된 결과 반환
        
        BI 도구는 OLAP의 구조를 상요해 데이터를 집계하기 위한 소프트웨어
        
        데이터 마트도 이전에는 OLAP 큐브로 작성됨
        
    - MPP DB와 비정규화 테이블
        
        MPP DB, 인메모리 DB의 보급 → 사전계산이 필요 없어짐
        
        BI도구 + MPP DB 조합해 크로스 집계를 많이 하게됨
        
        만들고 싶은 그래프에 맞춰 다차원 모델 설계를 위해 비정규화 테이블 사용
        
    - 테이블 비정규화
        - 트랜잭션: 시간과 함께 생성되는 데이터, 한번 기록하면 변화하지 않음
        - 마스터: 트랜잭션에 참고되는 각종 정보, 상황에 따라 변화
        - 아래의 판매이력: 트랜잭션, 나머지 마스터
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2018.png)
            
        - 데이터 웨어하우스에서는 트랜잭션 → 팩트 테이블, 마스터 데이터 → 디멘션 테이블이라고 함
        - 스타테이블과 비정규화
            
            데이터 마트를 만들 때, 아래처럼 팩트 테이블을 중심으로 여러 디멘션 테이블을 결합하는 것이 좋다
            
            위와 같이 정규화의 반대작업을 하기 때문에 비정규화 라고 함
            
            데이터 마트에서 스타 스키마가 사용되는 이유는 이해하기 쉽고, 성능이 좋음
            
            데이터 양이 증가하면서 팩트테이블이 디멘션 테이블보다 커져 데이터 양이 집계 시간을 좌우함. 팩트 테이블이 메모리 용량을 초과한 시점에 디스크 I/O가 발생하고, 대기시간이 쿼리의 지연으로 이어짐. → 팩트테이블을 ID와 키만 남도록하고 나머지는 디멘션 테이블로 구성해 팩트테이블을 최대한 작게 구성하는 것이 성능에 중요
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2019.png)
            
            ref. [https://itwiki.kr/w/스타_스키마](https://itwiki.kr/w/%EC%8A%A4%ED%83%80_%EC%8A%A4%ED%82%A4%EB%A7%88)
            
        - 비정규화 테이블
            
            하지만, 최근 MPP DB와 같은 열 지향 스토리지를 갖는 시스템 보급 증가해, 처음부터 테이블에 모든 칼럼을 포함하고, 쿼리실행 시에는 테이블 결합을 하지 않는 것이 간단함
            
            열지향 스토리지는 칼럼단위로 데이터 압축을 하기 때문에, 디스크 I/O증가는 억제됨
            
            데이터 마트에 스타 스키마를 사용하는 것은 과거, 성능 문제는 열지향 스토리지에 의해 해결됨.
            
            비정규화 테이블: 아래의 3번처럼 스타스키마에서 더 비정규화를 진행해, 모든 테이블을 결합한 테이블. 대부분 데이터마트는 비정규화 테이블로 하는 것이 단순하며, 효율적
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2020.png)
            
            cf) 데이터 웨어하우스는 스타 스키마로 작성하는 것이 좋음
            
            cf) [https://www.slideshare.net/datamgmt/using-the-right-data-model-in-a-data-mart](https://www.slideshare.net/datamgmt/using-the-right-data-model-in-a-data-mart)
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2021.png)
            
        - 다차원 모델 시각화에 대비한 테이블 추상화
            
            비정규화 테이블을 준비했으면 다차원 모델에 의해 추상화 
            
            다차원 모델은 디멘션(행과 열을 이용한 것)과 측정값(집계방법 정의)으로 분류함, 예시 & 태블로
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2022.png)
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2023.png)
            
            BI 도구 이용 시, 시각화하고 싶은 측정값 디멘션 결정 → 데이터 마트에 비정규화 테이블 구축 → BI 도구 시각화 → 새로운 집계 원함 → 비정규화테이블에 새로운 칼럼 추가 → BI도구 시가화
            
        - 요약: 피벗테이블, 크로스집계, 열지향 스토리지, MPP DB, 애드혹분석, 데이터마트, BI도구, 팩트테이블, 디멘션 테이블, 비정규화테이블, MPP, 열지향 DB, OLAP, 다차원 모델, 측정값, 디멘션
        

## 3장 빅데이터 분산 처리

## 3.1 대규모 분산 처리의 프레임워크

- 구조화 데이터와 비구조화 데이터
    - 스키마: SQL의 테이블의 칼럼명 데이터형 테이블간의 관계를 명시
    - 구조화 데이터: 스키마가 명확하게 정의된 데이터
    - 반구조화 데이터(스키마리스): csv, json, xml
    - 비구조화 데이터: 자연어, 이미지, 영상
    - Data Lake(데이터 레이크): 비구조화 데이터를 분산스토리지에 저장하고 분산시스템에서 처리하는 것. 데이터 가공과정에서 스키마 정의, 구조화 데이터로 변환해 분석 가능.
- 스키마리스 데이터
    - csv, json, xml등의 서식은 있지만 칼럼 수나 데이터 형은 명확하지 않는 데이터
    - NoSQL DB는 스키마리스 데이터에 대응, 데이터 레이크에서는 대량으로 축적된 스키마리스 데이터를 효율적으로 처리하도록 하는 요구도 있음
    - 새로운 데이터를 받을 때마다 스키마를 정하는 것은 시간 비용 up → json을 그대로 저장하고 데이터 분석해 필요한 필드만 추출하는 편이 간단함.
- 데이터 구조화의 파이프라인
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2024.png)
    
    이 책에서는 구조화 데이터는 항상 열지향 스토리지로 보관하는 것으로 가정
    
    구조화 데이터 중 시간에 따라 증가하는 데이터를 팩트테이블, 부속 데이터를 디멘션 테이블로 설정. 데이터 마트를 만드는 것은 이후의 이야기.
    
- 열지향 스토리지의 작성
    - MPP DB의 경우 제품에 따라 스토리지의 형식이 고정되어 있어 사용자가 상세를 몰라도됨
    - Hadoop에서는 사용자가 열지향 스토리지를 선택해, 원하는 쿼리 엔진에서 집계 가능
        - 사용가능한 열지향 스토리지 옵션이 여러 개 존재
            
            Apache ORC: 구조화 데이터를 위한 열지향 스토리지, 처음에 스키마를 정한 후 데이터 저장 (ORC를 가정하고 책 진행)
            
            Apache Parquet: 스키마리스에 가까운 데이터 구조, json과 같은 데이터 그대로 저장 가능
            
        - 비구조화 데이터를 읽어 열지향 스토리지로 변환하는 가공 압축은 많은 컴퓨터 리소스가 사용됨 → 하둡과 스파크 등의 분산처리 프레임워크를 사용하는 이유
- Hadoop
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2025.png)
    
    - 하둡은 단일 소프트웨어가 아니라 분산시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체
    - 분산시스템의 구성요소
        - 분산 파일 시스템: HDFS(Hadoop Distributed File System)
        - 리소스관리자: YARN(Yet Another Resource Negotior)
        - 분산데이터처리: MapReduce
    - 이외 프로젝트는 하둡의 본체와 독립적으로 개발되 하둡을 이용한 분산 앱으로 동작함
        - HDFS, Mesos, Spark와 같이 구성 가능
- 분산파일 시스템과 리소스 관리자
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2026.png)
    
    - HDFS
        - 하둡의 데이터는 대부분 HDFS에 저장
        - 네트워크에 연결된 파일 서버와 같음
        - 다수의 컴퓨터에 파일을 복사해 중복성을 높임
    - YARN
        - CPU 메모리 등의 계산 리소스 관리
        - 애플리케이션이 사용하는 CPU 코어와 메모리를 컨테이너 단위로 관리 (도커와 같이 OS수준의 가상화가 아니라, 호스트에서 어떤 프로세스를 실행시킬 것인지 결정하는 애플리케이션 수준의 기술)
        - 하둡에서 분산 애플리케이션 실행 → YARN이 클러스터 전체의 부하를 보고 비어있는 호스트부터 컨테이너 할당
        - 어느 애플리케이션에 얼마만큼의 리소스를 할당할지 관리 → 모든 애플리케이션이 실행되도록 제어
        - 애플리케이션마다 실행의 우선순위 결정 가능
    - Apache Mesos
        
        OS수준의 가상화 기술 사용. YARN보다 엄격한 리소스 제어. 도커와 함께 리눅스 컨테이너 사용하며 도커 이미지 사용해 프로그래밍 실행 가능
        
        HDFS와의 연계된 애플리케이션 실행은 YARN이 더 우수
        
- 분산데이터처리 / 쿼리엔진
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2027.png)
    
    - MapReduce: YARN 위에서 동작하는 분산 애플리케이션으로 데이터 처리에 사용. 임의의 자바 프로그램을 실행가능해 비구조화 데이터 가공에 적합. 작은 프로그램에게 적합하지 않음.
    - Apache Hive: SQL 등 쿼리언어에 의한 데이터 집계. 초기 Hive는 맵리듀스에 의존했음.
- Hive on Tez
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2028.png)
    
    - 기존 맵리듀스 대체 목적으로 개발, 스테이지 사이의 대기시간 감소
    - 현재 Hive 는 맵리듀스와 Tez를 사용해도 동작하도록 재작성 되어 있음 (cf. Hive on Spark도 개발 진행되고 있음)
- 대화형 쿼리엔진
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2029.png)
    
    - Impla, Presto: Hive 고속화하는 것이 아니라 쿼리의 실행만 전문으로 하는 쿼리엔진
    - 리소스를 최대한 활용해 쿼리를 실행. MPP DB에 신속한 집계 성능.
    - 대량의 비구조화 데이터 가공하는 배치처리에는 높은 처리량으로 리소스를 활용가능한 Hive를 사용 → 이 후의 완성한 구조화 데이터를 대화식으로 집계할 때는 지연이 적은 Implal와 Presto 사용.
- Spark
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2030.png)
    
    - 맵리듀스보다 효율적 데이터 처리 실현을 목적으로 진행된 프로젝트
    - 대량의 메모리를 활용해 고속화 실현 → 시대적으로 컴퓨터의 메모리 양 증가 → 가능한 많은 데이터를 메모리에 올리고 디스크에는 기록하지 않는 것, 비정상 종료 시 처리를 다시 실행
    - 맵리듀스 대체
        - HDFS, YARN 적용 가능, HDFS 대신 Amazon S3/카산드라 적용 가능
        - 실행은 자바런타임이 필요하지만, 스파크 상의 데이터 처리는 스크립트 언어 사용가능. 표준으로 자바, 스칼라, 파이썬, R 지원
        - SparkSQL, Spark Streaming 기능들 존재

## 3.2 쿼리 엔진

- 데이터마트 구축 파이프라인
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2031.png)
    
    하이브와 프레스토를 결합한 데이터 파이프라인 예시
    
    하이브를 이용해 여러 텍스트파일을 통해 열지향 스토리지로 저장
    
    프레스토를 이용해 데이터를 결합 집계해 데이터 마트로 만듬
    
- 하이브를 이용한 구조화 데이터 작성
    - 외부테이블: 하이브 외부의 파일을 참고해 테이블이 있는 것처럼 읽어드리는 것
        
        Hive와 같은  SQL on Hadoop 쿼리엔진은 MPP DB처럼 데이터를 내부로 가져오지 않아도 파일을 그대로 집계 가능 → 애드혹 분석에 유용하지만 빠르지는 않음 → 열 지향 스토리지로 변환
        
    - Hive의 열지향 스토리지로 변환
        
        테이블을 열지향 스토리지 형식 ORC(Optimized Row Columnar)로 Hive 변환 예시
        
        - 변환 작업에는 시간이 걸림
        - 외부 테이블과 테이블 집계시간 비교: 8.6sec → 1.5sec
        - 외부 테이블과 파일 크기비교: csv 파일 → orc  1/10 이하
        
        Hive는 텍스트나 스키마리스 데이터 중 Hive에서 읽을 수 있는 형식이면 쿼리를 통해 변환 가능
        
- Hive의 비정규화 테이블 작성
    
    비정규화 테이블을 대화형 쿼리엔진인 프레스토나 배치형 쿼리 엔진 하이브에 따라 다름
    
    비정규화 테이블이 수억 레코드 이상이면 하이브를 사용하는 것이 리소스 이용 효율에 좋음
    
    하이브의 비정규화 테이블 작성의 효율적인 쿼리 작성 방법
    
    공신문서의 모범사례를 참고하는 것이 좋음
    
    - 하이브 쿼리에서는 서브쿼리안에서 레코드 수를 줄이는 방법
        
        하이브는 SQL과 유사하지만 특성은 일반적인 RDB와는 다름. 읽어들이는 데이터 양을 의식하면서 쿼리를 작성해야 성능이 좋음.
        
        ex. join 이전에 조건으로 데이터양 감소 시키기
        
        ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2032.png)
        
    - 데이터 편향 피하기
        
        분산시스템에서 selct count(distinct col)은 오래걸릴 수 있다. 아래 예시에서는 group by를 이용해 데이터를 분할할 때 날짜 별로 데이터의 양이 균일해 오래걸리지 않지만, 데이터의 편차가 클 때는 시간이 오래 걸릴 수 있다. 편차를 최대한 없애고 노드에 데이터가 균등하게 분산되도록 하면 보다 부하를 줄일 수 있다.
        
        ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2033.png)
        
- 대화형 쿼리엔진 & Presto
    - 하둡과 함께 사용하는 대화형 쿼리 엔진: 구글 빅쿼리(dremel 기반), 아파치 임팔라, 아파치 드릴, 프레스토, Dremel
    - 작은 쿼리를 여러 번 실행하는 데이터 처리에 적합, 쿼리 실행 지연 감소 목적
    - 프레스토: 1.0버전을 출시하진 않았지만, AWS에 포함 등의 다수 프로젝트에 이용됨
        
        ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2034.png)
        
        Hive와 같이 다양한 데이터 소스에서 직접 데이터를 읽음
        
        다수의 컴퓨터에서 실행되는 분산 시스템
        
        쿼리가 프레스토 CLI로 입력되면 코디네이터가 쿼리를 분석해 계획 수립 후 워커에게 처리를 분배
        
        수백만 레코드에서 1초 미만으로 집계
        
        - 플러그인 가능한 스토리지
            
            하나의 쿼리에 여러 데이터 소스에 연결이 가능
            
            csv 로드는 하이브와 비슷하지만, ORC형식에 최적화되어 있음
            
            하이브 메타스토어 이외에, MySQL의 마스터 테이블과 분산스토리지 상의 테이블의 조인이나 NoSQL DB와의 집계도 가능
            
        - CPU 처리의 최적화
            
            프레스토는 SQL 실행에 특화됨
            
            쿼리를 분석 → 최적 실행 계획 생성 → 자바 바이트 코드로 변환 → 워커노드 배포 → 런타임 시스템에 기계 코드로 컴파일
            
            코드 실행시 멀티 스레드화 되어 단일 머신에서 병렬로 실행
            
        - 인메모리 처리에 의한 고속화
            
            하이브와 다르게 프레스토는 디스크에 쓰지 않고 모든 데이터 처리를 메모리 상에서 실시하고 부족하면 여유있을 때 까지 기다리거나 오류 발생
            
        - 분산 결합, 브로드캐스트 결합
            
            프레스토는 기본적으로 분산결합 수행. 노드간의 데이터 전송에서 네트워크 통신으로 인해 쿼리 지연 초래.
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2035.png)
            
            한쪽 테이블이 작은 경우 브로드 캐스트 결합을 사용해 처리 속도 개선 가능. 이 때는 데이터가 각 노드에 복사됨.
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2036.png)
            
- 데이터 분석 프레임워크 선택
    
    MPP DB, Hive, Presto, Spark 비교
    
    - MPP 데이터 베이스 - 완성화된 비정규화 테이블 고속 집계 적합
        
        기능 성능 안정성에는 하둡 기반의 기술보다는 좋음
        
        확장성, 유연성 측면에서는 하둡 기반의 기술보다는 떨어짐
        
        ex. 대량 텍스트 처리 → NoSQL과 분산시스템 결합 필요
        
        시각화는 BI도구와의 결합하여 고속집계에 적합
        
    - Hive - 데이터 양에 좌우되지 않는 쿼리 엔진
        
        하둡기반 → 높은 확장성, 내결함성(fault-tolerance)
        
        텍스트 가공, 열지향 스토리지 구축 등의 무거운 대규모 배치처리에 적합
        
    - Presto - 속도 & 대화식에 특화된 쿼리 엔진
        
        하이브와 반대로 내결함성이 약하고, 메모리 부족시 오류 발생 가능 → 실행이 빨라 다시 쿼리 가능
        
        하둡, MYSQL, 카산드라, 몽고DB 등의 데이터 스토어에 적용 가능
        
        텍스트 처리 중심의 ETL프로세스 / 데이터 구조화에는 적합하지 않음 → Hive & Spark가 적합
        
    - Spark - 분산 시스템을 사용한 프로그래밍 환경
        
        ETL프로세스에서 SQL에 이르는 흐름을 하나의 데이터 파이프라인으로 기술 가능
        
        데이터 구조화 Hive & 쿼리 Presto 의 흐름 → Spark 하나의 스크립트로 실행 가능
        
        메모리 관리가 중요. 데이터 캐시, 스왑 등의 제어 가능.
        

## 3.3 데이터 마트 구축

- 팩트테이블
    - 데이터 구조화에서 가장 많은 부분을 차지
    - 팩트 테이블 작성 - 추가와 치환
        
        ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2037.png)
        
        - 추가 (append): 새로 도착한 데이터 추가
            
            효율은 압도적으로 치환에 비해 좋지만, 잠재적 문제 존재
            
            추가 실패 시 결손 발생, 중복가능, 스키마 변경 어려움
            
            → 테이블 파티셔닝 
            
            하나의 테이블을 여러 물리적 파티션으로 나눠, 파티션 단위로 정리해 데이터를 쓰거나 삭제
            
            1일 1회 or 1시간 1회 새 파티션을 만들고 팩트테이블에 붙임
            
            ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2038.png)
            
        - 치환 (replace): 과거데이터를 포함해 전체 데이터 구성
            
            데이터 웨어하우스 구축에 유용. 데이터 중복, 빠뜨릴 가능성이 거의 없음. 스키마 변경에 유연.
            
            처리시간이 김
            
- 집계 테이블(summary table)
    
    집계테이블을 통해 데이터 마트의 크기 감소
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2039.png)
    
    카디널리티: 각 칼럼이 취하는 값의 범위
    
    디멘션의 카디널리티를 줄여 측정값을 집계
    
    ex. IP주소의 위치정보로 변환 → 카디널리티 감소
    
    정보가 손실되지 않는 선에서
    
- 마스터 테이블의 변화 기록
    - 스냅샷 테이블: 정기적으로 테이블을 통째로 저장
        
        팩트테이블과 마스터 데이터와 결합해 디멘션 테이블로 사용 가능. 스냅샷으로 날짜를 지정해 과거의 마스터 테이블 확인 가능.
        
        ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2040.png)
        
        ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2041.png)
        
    - 이력서 테이블(history table): 변경 내용만 저장
        
        마스터 변화의 복원은 어려워 디멘션 테이블로 사용은 어려움
        
- 비정규화 테이블 완성
    
    마지막 단계로 디멘션 테이블을 결합해 비정규화 테이블을 만듬
    
    디멘션 테이블로 스냅샷과 중간테이블이 만들어짐
    
    ex. 세션 ID를 통해 사용자 동향 분석, 웹사이트 액세스 해석
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2042.png)
    
    ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2043.png)
    
    - 데이터 집계의 전형적 쿼리
        
        ![Untitled](%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF%20%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%201-3%201b7564ad16614c34a038c652a32c4bb1/Untitled%2044.png)
        
        1. 팩트 테이블에 필요한 데이터 로드: 시간에 의한 검색, 참고 컬럼 수 줄임으로 로드속도 향상
        2. 디멘션 테이블과 결합해 데이터 마트에 저장할 칼럼 선택: 카디널리티를 작게, 시각화에 사용하고자 하는 디멘션 추가
        3. 그룹화를 통해 측정값 집계