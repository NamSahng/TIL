{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 3 Orthogonality\n",
    "\n",
    "#### Orthogonal vectors and subspace\n",
    "\n",
    "- Why orthogonality is important. <br>\n",
    "indipendent basis, easy calculation in linear combination <br>\n",
    "\n",
    "- length of vectors <br>\n",
    " $ \\parallel X \\parallel ^{2} = X^{T}X = \\sum_{i=1}^{n}x_{i}^{2} $\n",
    "\n",
    "- If nonzero vectors v1, ... vk are mutualy orthogonal, then the vectors are linearly independent.<br>\n",
    "pf) c1v1 + c2v2 + ... + cnvn = 0 을 만족하는 cn 들은 0들 밖에 없는지.<br>\n",
    "$ v_{i}^{T} $를 양 변에 곱해, $ ci \\parallel V_{i} \\parallel ^{2} = 0 $ <br>\n",
    "만족하는 ci는 0밖에 없음을 알 수 있다.<br>\n",
    "그러면이제 orthogonal vector들이 basis가 될 수 있고 span할 수 있다. 그리고 이를 span한 ortogonal 한 vector 들의 크기를 1로 만들면 orthonormal하다고 한다.  $  \\parallel V_{i} \\parallel ^{2} = 1 $\n",
    "\n",
    "- Easy calculation. <br>\n",
    "linearly independent한 벡터 a1, a2, .. an에 대해 $ X = \\sum C_{i}a_{i} $를 x가 주어졌고 c를 푸는 문제 G.E를 통해 풀어야하는데, a1, ... an을 orthognal한 벡터로 사용하면 $ V_{i}^{T}X = C_{i}\\parallel V_{i} \\parallel ^{2} $을 이용해 쉽게 풀 수 있다.\n",
    "\n",
    "- Orthogonal Subspaces <br>\n",
    "If two subspaces are mutually orhgonal, then every vector in on subspace is orthogonal to every verctor in the other subspace. <br>\n",
    "ex) Row space $ \\perp $ Null space 그리고 $ Dim( \\mathbf{C}(A)) + Dim( \\mathbf{N}(A^{T})) = r + m - r = m   $   <br>\n",
    "    Column space $ \\perp $ Left Null space $ Dim( \\mathbf{C}(A^{T})) + Dim( \\mathbf{N}(A)) = r + n - r = n $ <br>\n",
    "예를 들어, col space가 3차원에서 직선이면, left null space는 그 직선과 대응되는 평면인 서로 보완적인 관계이다. 이러한 관계를 Orthogonal Complement Subspace라고 한다.<br>\n",
    "3차원에서 수직인 직선 2개는 complementary한 관계는 아니지만 2차원에서는 orthogoanl complementary의 관계이다. <br>\n",
    "두 subspace의 수직을 보여라 $ \\to $ 두 subspace의 basis들의 내적값이 0임을 보이면 된다. \n",
    "\n",
    "<img  src=\"./image/image_3.4.PNG\" width=\"70%\">\n",
    "\n",
    "#### Cosines and Projections onto lines.\n",
    "\n",
    "- Inner product and cosines.<br>\n",
    "$ || b - a ||^{2} = ||a||^{2} + ||b||^{2} - 2||a||||b||\\cos\\theta$\n",
    "$ (b - a)^{T}(b - a) = a^{T}a + b^{T}b - 2||a||||b||\\cos\\theta$\n",
    "$ a^{T}b = ||a|| ||b|| \\cos\\theta $\n",
    "\n",
    "-  Projections onto a line. <br>\n",
    "projection point p (closest point from point b), projection  of vector b onto vector a. <br>\n",
    "$ p = \\hat{x}a = {{a^{T}b}\\over{a^{T}a}}a $ <br>\n",
    "Procection Matrix <br>\n",
    "$ \\mathbf{P} = {{aa^{T}}\\over{a^{T}a}} $ <br>\n",
    "$ \\mathbf{P}^{2} = p $ 수학적으로 선형대수 이외에도 p제곱이 p를 만족하는 것들을 projection이라고 한다.<br>\n",
    "여기서 a를 vector space로 확장하고 a를 행렬로 바꾸면 <br>\n",
    "$ p = \\hat{x}A = A(A^{T}A)^{-1}A^{T}b $\n",
    "\n",
    "#### Projections and Least Squares\n",
    "\n",
    "Square system $ \\to $ G.E. $ \\to $ Upper Triangular. (Chapter1) <br>\n",
    "Underconstrained System: Rectangular system when # of Equation < # of Unknowns $ \\to $ G.E. $ \\to $ Reduced Row Echelon form (Chapter2)\n",
    "\n",
    "Overconstrained System: Rectangular system when # of Equation > # of Unknowns, usually no solution. \n",
    "\n",
    "Ax = b를 만족하는 해가 없으니 (inconsistent) $ ||Ax-b|| $를 최소화하는 제일 적절한 Column space의 solution을 찾자. (Use Projection! $ min||Ax-b||^{2} $ 하자 $ \\to $ Least Square Solution) \n",
    "\n",
    "<img  src=\"./image/image_3.8.PNG\" width=\"70%\">\n",
    "\n",
    "error $ E = || Ax - b || $, is  distance from  to the point Ax in the Column space.  <br>\n",
    "error vector $ e = b - A\\hat{x} $, must be perpendicular to the Column space.\n",
    "\n",
    "Finding $ \\hat{x} $ and the projection is so fundamental the we do it in 2 ways: <br>\n",
    "1) The error vector must be orthogonal to each column vector <br>\n",
    "$ \\begin{bmatrix}  a_{1}^{T}  \\\\  \\vdots \\\\  a_{n}^{T}  \\end{bmatrix} \\begin{bmatrix} b-A\\hat{x} \\end{bmatrix} = 0 \n",
    "$<br>\n",
    "2) Since Column space is perpendicular to left null space, The error vector ($ e = b - A\\hat{x} $ must be in the nullspace of $ A^{T} $(left null space).<br>\n",
    "$ A^{T}(b - A\\hat{x}) = 0 \\ \\ $ or $ \\ \\ A^{T}A\\hat{x} = A^{T} b$ \n",
    "\n",
    "- Normal form ( $ A^{T}A $의 역행렬이 항상 존재하지 않으니) : $ A^{T}A \\hat{x} =  A^{T} b $ <br>\n",
    "- Best estimate : $  \\hat{x} =  (A^{T}A)^{-1}A^{T} b $  and  $(A^{T}A)^{-1}$ can be pseudo inverse\n",
    "- Projectioin Matrix: $ \\mathbf{P} = A (A^{T}A)^{-1}A^{T} $, Point: $ p = A\\hat{x} = \\mathbf{P}b = A (A^{T}A)^{-1}A^{T}b $ \n",
    "\n",
    "ex) x + 2y - 3z = 0의 평면의 projection matrix. <br>\n",
    "평면을 지나는 두 independent 한 vector로, (1,1,1), (3,0,1)(아무거나)으로 $ A = \\begin{bmatrix} 1 & 3 \\\\ 1 & 0 \\\\ 1 & 1 \\end{bmatrix} $ 를 만들어 공식을 사용하면됨. <br>\n",
    "x + 2y - 3z = b이면 0으로 놓고 평행이동을 활용.\n",
    "\n",
    "- Least Square for Line fitting.<br>\n",
    "다음과 같은 데이터( (x1,y1)... (xn,yn) )로 부터 에러를 최소화하는 직선을 구하는 것. <br>\n",
    "$ y_{1} = ax_{1} + b , \\  y_{2} = ax_{2} + b, \\ ... y_{n} = ax_{n} + b $ 에서 error를 최소화 하는 직선 a,b <br>\n",
    "$ \\begin{bmatrix} \n",
    "x_{1} & 1 \\\\ \n",
    "x_{2} & 1 \\\\ \n",
    "\\vdots & \\\\ \n",
    "x_{n} & 1 \\end{bmatrix}  \\begin{bmatrix} a \\\\ b \\end{bmatrix} =  \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} $ <br>\n",
    "error의 형태는 Ax-b의 형태이므로 <br>\n",
    "$ \\begin{bmatrix} \n",
    "ax_{1} + b - y_{1} \\\\ \n",
    "\\vdots \\\\\n",
    "ax_{n} + b - y_{n} \\end{bmatrix} \\to || Ax - b ||^{2} = \\sum_{i=1}^{n} (ax_{i} + b - y_{i})^{2} $\n",
    "\n",
    "이때 $ A^{T}A =  \\begin{bmatrix} \\sum_{i}^{n} x_{i}^{2} & \\sum_{i}^{n} x_{i} \\\\ \\sum_{i}^{n} x_{i} & n  \\end{bmatrix} $ 으로 나와 이것의 inverse를 활용해 구할 수 있다. $ \\hat{x}a = {{a^{T}b}\\over{a^{T}a}}a $ \n",
    "\n",
    "cf) $ f(x) = (x-a_{1})^{2} + ... + (x-a_{n})^{2} $의 최소 값 $ x = {{\\sum_{i=1}^{n}a_{i}}\\over{n}} \\to $ 평균, 위에도 두 점들을 이은 직선들의 평균이다.\n",
    "\n",
    "또는 미분을 활용해 $ || Ax - b ||^{2} = \\sum_{i=1}^{n} (ax_{i} + b - y_{i})^{2} = f(a,b) $ 이니까.<br>\n",
    "각각의 편미분을 활용해, $ \\partial f / \\partial a = 0 , \\partial f / \\partial b = 0   $ a,b를 구해도 결과는 위와 같다.\n",
    "\n",
    "Assignment)  지수함수의 곡선에 8 개의 점들 샘플에 에러를 추가해 2차, 3차 곡선으로 fitting 해 보는 것. (matlab으로) $ y = ax^{2} + bx + c $ 로 놓고\n",
    "\n",
    "$ \\begin{bmatrix} \n",
    "x_{1}^{2} & x_{1} & 1 \\\\ \n",
    "x_{2}^{2} & x_{2} & 1 \\\\ \n",
    "& \\vdots & \\\\ \n",
    "x_{n}^{2} & x_{n} & 1 \\end{bmatrix}  \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} =  \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix} $ \n",
    "\n",
    "실제로는 노이즈가 없는 데이터들만 취하기 위해 Random Sample Consensus (RANSAC)이라는 것을 한다. 또한 Ax = B에서 Weight(확률)을 곱해 푸는 것이 좀더 일반적이다.\n",
    "\n",
    "선형대수에서 가장 중요한 3가지 개념 (G.E. , Projection & Least , Eigen Value Vector.)\n",
    "그중 베스트오브 베스트는 위에 것.\n",
    "\n",
    "\n",
    "\n",
    "#### Orthogonal Basis & Gram-Schmidt\n",
    "\n",
    "let $ q_{1}, ..., q_{n} $ are orthonormal. then $ q_{i}^{T}q_{j} = 1 \\ or \\ 0 $ (if i = j, 1 else 0)\n",
    "\n",
    "let $ Q =  \\begin{bmatrix} q_{1} & ... & q_{n}  \\end{bmatrix}  $ then $ Q^{T}Q = I \\to Q^{T} = Q^{-1} $ transpose is left inverse. <br>\n",
    "ex) Rotationi Matrix, Permutation Matrix. (이 2개라고 봐도 무방) <br>\n",
    "Q transformation preserves the length and angle. Projectcon reduces the length.\n",
    "\n",
    "for $ q_{1}, ... q_{n} \\in \\mathbf{R}^{n} $,  $ Q =\\begin{bmatrix} q_{1} & ... & q_{m}  \\end{bmatrix}   $ (m <= n) 인 것만 존재한다. (식이더 많은) Q는 rectangular system 에서 left inverse 만 존재.\n",
    "\n",
    "- Gram-Schmidt Orthogonalization <br>\n",
    "Finding the Orthonormal basis from given Independent vectors <br>\n",
    "1) for the first vector, $ a \\to {{a}\\over{||a||}} = q_{1} $ make length 1 <br>\n",
    "2) for the next vector b project onto q1 <br> \n",
    "$ {{q_{1}^{T}b}\\over{q_{1}^{T}q_{1}}}q_{1} = ({q_{1}^{T}b})q_{1}$ (분모의 길이 1)와 수직임을 활용 ($ (b-({q_{1}^{T}b})q_{1}) \\perp q_{1} $ ) $ {{b-({q_{1}^{T}b})q_{1}} \\over { || b-({q_{1}^{T}b})q_{1} ||}} = q_{2}$ <br>\n",
    "$ \\to $ $ a_{j} - \\sum_{i=1}^{j-1}(q_{i}^{T}a_{j})q_{i} = A_{j} $<br>\n",
    "3) vector b를 q1과 q2로 표현하면, $ b = ({q_{1}^{T}b})q_{1} + ({q_{2}^{T}b})q_{2} $ 이니까, $ ( c - ( ({q_{1}^{T}b})q_{1} + ({q_{2}^{T}b})q_{2} )) \\perp q_{1}, q_{2}  $ 이고 왼쪽 것을  Normalization 해주면됨.<br>\n",
    "$ \\to $ $ {{A_{j}} \\over {|| {A_{j}} ||}} = q_{j} $ (이 때, Aj가 너무 작으면 0에 가까우면, 버린다.)\n",
    "\n",
    "- A = QR Factorization <br>\n",
    "\n",
    "$ \\begin{bmatrix} a_{1} & \\cdots &  a_{n} \\end{bmatrix} =\n",
    "\\begin{bmatrix} (q_{1}^{T} a_{1})q_{1} & (q_{1}^{T} a_{2})q_{1} + (q_{2}^{T} a_{2})q_{2} &   \\cdots &  \\sum_{i=1}^{n} (q_{i}^{T} a_{n})q_{i} \\end{bmatrix} =  \\begin{bmatrix} q_{1} & \\cdots &  q_{n} \\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "(q_{1}^{T} a_{1}) & (q_{1}^{T} a_{2}) & \\cdots & (q_{1}^{T} a_{n}) \\\\\n",
    "0 & (q_{2}^{T} a_{2}) & \\ddots & \\vdots \\\\\n",
    "\\vdots & \\vdots & \\vdots  &  \\vdots \\\\\n",
    "0 & 0 & 0  &  (q_{n}^{T} a_{n})\n",
    "\\end{bmatrix} = QR $\n",
    "\n",
    "QR decomposition의 좋은점: Least square 에서 $ \\hat{x} = (A^{T}A)^{-1}A^{T} b =  (R^{T}Q^{T}QR)^{-1}R^{T}Q^{T} b = R^{T}RR^{T}Q^{T}b $ 임을 활용해 H/W 연산을 빠르게 할 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Spaces and Fourier Series \n",
    "\n",
    "- Function Space (Hilbert Space): 함수를 벡터처럼 다루는 것.\n",
    "\n",
    "\n",
    "- expand Vector Space to Functions. <br>\n",
    "$ Vector Space \\in R^{n} \\to Hilbert Space \\in R^{\\infty} $ <br>\n",
    "$ x(t), y(t) \\in \\mathcal{H} \\qquad (a \\le t \\le b) $ <br>\n",
    "$ x(t) + y(t)  \\in \\mathcal{H} $  , $  \\alpha x(t) \\in \\mathcal{H} $ (알파는 스칼라) Vector space와 같이 닫혀있다. \n",
    "\n",
    "\n",
    "- Vector: $ V = (v_{1}, ... , v{n})^{T} $<Br>\n",
    "$ \\to \\lim_{\\Delta t \\to 0} x(t) = (x(a), x(a+\\Delta t), x(a+e\\Delta t), .... , x(b))^{T} $\n",
    "\n",
    "\n",
    "- Vector Inner Product $ \\to $ Function Inner Product  <br>\n",
    "$ X^{T}Y = \\sum_{i=1}^{n} x_{i}y_{i}  $ <br>\n",
    "$ (x(t),y(t)) = \\lim_{\\Delta t \\to 0} \\sum_{k=0}^{\\infty} x(a+k\\Delta t)y(a+k\\Delta t) = \\int_{a}^{b} x(t)y(t) dt  $<br>\n",
    "$ || x(t) ||^{2} =  \\int_{a}^{b} x^{2}(t) dt $\n",
    "\n",
    "\n",
    "- Orthogonality <br>\n",
    "$ X^{T}Y = 0 $ <br>\n",
    "$ (x(t),y(t))  = \\int_{a}^{b} x(t)y(t) dt = 0 $ 일 때, 두 함수는 수직이라 한다. <br>\n",
    "\n",
    "\n",
    "- Basis Vectors $ \\to $ Basis Functions <br>\n",
    "$X = \\sum_{i=1}^{n} a_{i}v_{i} \\to x(t) = \\sum_{i=0}^{\\infty} a_{i}b_{i}(t) $ <br>\n",
    "이러한 무한한 linear combination을 series라고 한다.<br>\n",
    "$ \\sum_{i=1}^{n} (q_{i}^{T}a)q_{i} \\to x(t)  \\sum_{i=0}^{\\infty} (q_{i}(t),a_{i}(t))q_{i}(t) $\n",
    "\n",
    "\n",
    "- If given a basis Vector $ \\to $ Linear combination $ \\left\\{a_{i}'s \\right\\}  $ are unique! <br> If given a basis Function $ \\to $ Series coefficients are unique! <br>\n",
    " Especially $ \\left\\{ cos(nt), sin(mt) \\right\\} , (0 \\le t \\le 2\\pi) , m, n = int $을 basis 로 사용. m = n = 0 이면 DC 성분이라함. <br>\n",
    "m과 n은 frequency를 결정하며 이는 # of ascillation in a period(2pi)를 의미.\n",
    "\n",
    "\n",
    "- Fourier Series: orthogonal 한 함수 $ \\left\\{ cos(nt), sin(mt) \\right\\} $(basis) 를 갖고 특정 주기$ (0 \\le t \\le 2\\pi $)에서 함수를 해석하는 것. <br>\n",
    "$ x(t) = \\sum_{n=0}^{\\infty} a_{n}cos(nt) + \\sum_{m=0}^{\\infty}  b_{m}sin(mt) = \\sum_{k=0}^{\\infty} a_{k} e^{jkt} $ <br>\n",
    "an, bn을 모아 xt를 알 수 있고, 이를 통해 ASR, 음성합성과 같은 것을 할 수 있다.<br>\n",
    "\n",
    "\n",
    "- Gram-Schmidt for functions <br>\n",
    "$ a_{j} - \\sum_{i=1}^{j-1}(q_{i}^{T}a_{j})q_{i} \\perp q_{i} (i=1,2, ... j-1) $ <br>\n",
    "ex) $ 1, t, t^{2}, t^{3} ... (-1 \\le t \\le 1) $ <br>\n",
    "1) $ q_{1}(t) = 1 $ <br>\n",
    "2) $ t - (q_{1}(t), t)1 = t - \\int_{-1}^{1} t dt \\cdot 1 = t \\to q_{2}(t) $\n",
    "3) $ t^{2} - (q_{1}(t), t^{2}) q_{1}(t) - (q_{2}(t), t^{2}) q_{2}(t) = t^{2} -  \\int_{-1}^{1} t^{2}dt  \\cdot 1 - \\int_{-1}^{1} t^{2}\\cdot t dt \\cdot t   = t^{2} - 2/3 $ 이렇게 벡터와 같이 확장\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
