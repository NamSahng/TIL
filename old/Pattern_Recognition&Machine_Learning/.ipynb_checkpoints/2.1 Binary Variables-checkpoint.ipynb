{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률 분포는 자체로 흥미로울 뿐만아니라, 더 복잡한 모델을 만드는데 있어 중요한 역할을 차지한다.<br>\n",
    "여기서 말하는 분포의 역할은 한정된 수의 관찰 집합 $ \\mathbf{x_{1}}, ... , \\mathbf{x_{N}} $이 주어질 때 확률 변수 $ \\mathbf{x} $의 확률 분포 $ p(\\mathbf{x}) $를 모델링하는 것이다. 이를 ** 밀도 추정(Density Estimation) **문제 라고 한다.<br>\n",
    "우리는 데이터 포인트들은 독립적이며, 동일하게 분포되어있다고 가정할 것이다. 제한된 수의 관찰된 데이터 집합으로 가능한 모확률 분포의 가짓수는 무한대이기 때문에, 사실 밀도 추정문제는 근본적으로 타당하지 않다. 그러나 여러 분포 중 적절한 분포를 선택하는 것은 1장의 다항식 곡선 근사 문제와 연관되어 있으며 이는 패턴인식 문제의 중요 쟁점 중 하나이다.\n",
    "\n",
    "이산확률변수의 이항분포와 다항분포에 대해 살펴보고, 연속확률 변수의 가우시안 분포와 같은 **매개변수적(parametric) 분포**에 논의하자. 이러한 모델을 밀도추정문제에 적용하기 위해 관찰된 데이터 집합을 바탕으로 적절한 매개변수값을 구하는 과정이 필요하다.<br>\n",
    "이를 **빈도적관점(Frequenstic View)** 에서는 어떤 특정 기준을 최적화 하는 방식(가능도 함수와 같은)으로 매개변수를 찾는다.<br>\n",
    "**베이지안 관점(Bayesian View)**에서는 매개변수에 대한 사전 분포를 바탕으로 관측 데이터 집합이 주어졌을 때의 해당 사후 분포를 베이지안 정리를 활용해 계산한다.\n",
    "\n",
    "**켤레(Conjugate)** 사전 확률 또한 중요하다. 켤레 사전확률은 사후 확률이 사전확률과 같은 함수적 형태를 띠도록 만들어 주어 결과적으로 베이지안 분석이 단순해딘다. 예를 들어, 다항 분포 매개변수의 켤레 사전확률은 **디리클레 분포(Dirichlet Distribution)**이며, 가우시안 분포의 평균값의 켤레사전확률은 또 다른 가우시안 분포이다. 이 분포들은 모두 **지수족(Exponetial Family)**에 속한다. 지수족 분포들의 중요한 성질들 또한 살펴보자.\n",
    "\n",
    "매개변수적 접근법의 한계 중 하나는 분포가 특정한 하수의 형태를 띠고 있다는 가정한다는 것이다. 몇몇 적용 사례의 경우에는 적절하지 않아 이러한 경우에 **비매개변수적(nonparametric)** 밀도추정방식이 대안으로 활용가능하다. 비매개변수적 밀도 추정방식에서는 분포의 형태가 데이터 집합의 크기에 종속적이며, 이러한 모델은 여전히 매개변수를 가지고 있지만, 이 매개변수들은 분포의 형태를 결정짓는 것이 아니라 모델의 복잡도에 영향을 미친다. 마지막 부분에서는 히스토그램, 최근접 이웃, 커널을 바탕으로 하는 비개변수적 방법에 대해 살펴보자.\n",
    "\n",
    "### 2.1 Binary Variables (이산 확률 변수)\n",
    "\n",
    "하나의 이진 확률 변수 $ x \\in \\left\\{ 0, 1 \\right\\} $ 를 (예를 들어 x = 1은 동전 던지기의 앞면) 생각해보자. x=1일 확률은 매개변수 $\\mu$를 통해 $ p( x=1| \\mu ) = \\mu $ 로 표현할 수 있으며 여기서, $\\mu$는 $ 0 \\leqslant \\mu \\leqslant 1 $ 이며 $ p( x=0| \\mu ) = 1 - \\mu $이다. 따라서 이에 대한 확률 분포를 다음으로 적을 수 있다.\n",
    "$$ Bern(x|\\mu) = \\mu^{x}(1-\\mu)^{1-x} $$\n",
    "이를 **베르누이 분포(Bernoulli Distribution)**라고 하며 이는 정규화되어 평균과 분산이 다음과 같음을 쉽게 증명 가능하다.\n",
    "$$ \\mathbb{E} \\left[ x \\right] = \\mu $$\n",
    "$$ var \\left[ x \\right] = \\mu(1-\\mu) $$\n",
    "x의 관측 데이터 집합 $ \\mathcal{D} = \\left\\{ x_{1}, ... , x_{N} \\right\\} $로 주여졌으면 관측값들이 $ p(x|\\mu) $에서 독립적으로 추출되었다는 가정하에 $\\mu$에관한 함수로 다음과 같이 가능도 함수를 만들 수 있다.\n",
    "$$ p(\\mathcal{D} |\\mu) = \\prod_{n=1}^{N} p(x_{n}|\\mu) = \\prod_{n=1}^{N} \\mu^{x}(1-\\mu)^{1-x}  $$\n",
    "빈도적 관점에서는 가능도 함수를 최대화하는 (또는 로그 가능도 함수를 최대화하는) $\\mu$를 찾아 $\\mu$의 값을 추정할 수 있다.([MLE MAP 설명 및 계산](https://github.com/NamSahng/Summary/blob/master/Intro2AI%26ML/W1%20MLE%20%26%20MAP.ipynb)) 베르누이 분포의 경우 로그가능도 함수는 다음으로 주어진다.\n",
    "$$ ln(p(\\mathcal{D} |\\mu)) = \\sum_{n=1}^{N}ln( p(x_{n}|\\mu)) = \\sum_{n=1}^{N} \\left\\{ x_{n} ln \\mu + (1-x_{n})ln(1-\\mu) \\right\\} $$\n",
    "로그 가능도함수는 오직 관측값들의 합인 $ \\sum_{n}x_{n} $을 통해서만 N개의 관측값 $x_{n}$과 연관된다는 점에 주목하자. 이 합은 **충분 통계랑(Sufficient Statistic)**의 예시 중 하나다. 충분 통계량의 중요성은 다음에 자세히 살펴본다. $ ln(p(\\mathcal{D} |\\mu)) $를 $\\mu$ 에 대해 미분해 이를 0과 같다하면 다음과 같은 MLE값을 구할 수 있다. \n",
    "$$ \\mu_{ML} = {{1}\\over{N}} \\sum_{n=1}^{N}x_{n} $$\n",
    "위 식은 **표본 평균(Sample Mean)**이라고도 한다. 데이터에서 x = 1인 관찰값의 수를 m 이라고 하면 $ \\mu_{ML} = {{m}\\over{N}}  $ 가 되며 이는 최대 가능도 체계하에서 동전의 앞면이 나올 확류은 데이터 집합에서 앞면이 나온 비율로 주어지게 되는 것이다.\n",
    "\n",
    "이는 동전을 3번 던져 앞면이 3번 다 나오면 앞면이 나올 확률의 MLE 값은 1이라는 것이다. 이것이 최대 가능도를 사용했을 때 발생하는 과적합과 연관된 극단적 예시이다. 잠시 후 $\\mu$에 대한 사전 분포를 바탕으로 더나은 결과를 도출하는 방법을 살펴보자.\n",
    "\n",
    "크기 N의 데이터가 주어졌을 때 x = 1인 관측값의 수 m에 대해 분포를 **이항 분포(Binomial Distribution)**라 하며 위 식 $ p(\\mathcal{D} |\\mu) = \\prod_{n=1}^{N} p(x_{n}|\\mu) = \\prod_{n=1}^{N} \\mu^{x}(1-\\mu)^{1-x} $ 을 통해 이항분포는 $ \\mu^{m}(1-\\mu)^{N-m} $에 비례하는 것을 알 수 있다. 정규화 계수를 구하기 위해 동전 던지기를 N번 했을 때 앞면이 m 번 나올 수 있는 가능한 모든 가짓수를 구해야한다. 따라서 이항분포를 다음과 같이 표현한다.\n",
    "$$ Bin(m|N,\\mu) = {n \\choose m} \\mu^{m}(1-\\mu)^{N-m}$$\n",
    "($ {n \\choose m} \\equiv {{N!}\\over{(N-m)!m!}} $)\n",
    "\n",
    "이항 분포의 평균과 분산은 연습문제 1.10을 통해 구할 수 있으며 연습문제에서는 사건들이 서로 독립적일 경우에 사건들의 합의 평균값은 평균값들의 합과 같으며, 사건들의 합의 분산은 분산들의 합과 같다는 것을 증명했다. $m=x_{1}, ... , x_{N} $이기 때문에 각각의 관측갑과 평균은 다음과 같으며 이 결과값들은 직접 미적분을 적용해 확인 가능 있다.\n",
    "$$ \\mathbb{E} \\left[ m \\right] = \\sum_{m=0}^{N}m Bin(m|N,\\mu) = N\\mu   $$\n",
    "$$ var \\left[ m \\right] = \\sum_{m=0}^{N}(m-\\mathbb{E} \\left[ m \\right])^{2} Bin(m|N,\\mu) = N\\mu(1-\\mu)  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Beta Distribution (베타 분포)\n",
    "\n",
    "$ \\mu_{ML} = {{m}\\over{N}}  $에서 최대 가능도 방법 (MLE)에서의 베르누이 분포의 매개변수 $ \\mu $에 대해 살펴 보았으며 이항 분포에서는 $\\mu $ 의 MLE값이 데이터의 x=1의 관측값의 비율로 계산되는 것을 보았다. 이 때 관측값이 적으면 심각한 과적합이 일어나기 쉬우므로 베이지안적 접근을 위해 $\\mu$에 대한 사전분포 $p(\\mu)$를 도입해야한다. 해석하기 쉽고 분석적으로 유용한 형태의 사전분포를 도입해보자.\n",
    "\n",
    "가능도 함수가 $\\mu^{x}(1-\\mu)^{1-x}$의 형태를 가진 인자들의 곱의 형태를 띤다는 것을 주목해 보면, $\\mu$와 $(1-\\mu)$의 거듭제곱에 비례하는 형태의 사전 분포를 선택하면 사전확률과 가능도 함수의 곱에 비례하는 사후 분포 역시 사전분포와 같은 함수적 형태를 가진다. 이러한 성질을 **켤레성(Conjugacy)**이라고 한다. 지금까지의 논의를 바탕삼아 사전분포로 **베타분포(Beta Distribution)**을 사용할 것이다.\n",
    "$$ Beta(\\mu|a,b) = {{\\Gamma(a+b)} \\over {\\Gamma(a)\\Gamma(b)}} \\mu^{a-1} (1-\\mu)^{b-1}  $$\n",
    "이 때, $\\Gamma(x)$는 $ \\Gamma(x) \\equiv \\int_{0}^{\\infty} u^{x-1}e^{-u} $과 같이 정의 되며 위 식의 계수는 베타분포가 정규화 되도록한다. $ \\int_{0}^{1} Beta(\\mu|a,b) d\\mu = 1 $  베타분포의 평균과 분산은 다음과 같다.\n",
    "$$ \\mathbb{E} \\left[ x \\right] = {{a}\\over{a+b}}  $$\n",
    "$$ var \\left[ x \\right] = {{ab}\\over{(a+b)^{2}(a+b+1)}} $$\n",
    "매개변수 a와 b는 이들이 매개변수 $\\mu$의 분포를 조절하여 **하이퍼파라미터(초매개변수 Hyperparameter)**라고 한다. 하이퍼파라미터에 따른 베타 분포의 그림은 다음과 같다.\n",
    "\n",
    "<table width = \"70%\">\n",
    "<colgroup>\n",
    "<col width=\"10%\" />\n",
    "<col width=\"10%\" />\n",
    "</colgroup>\n",
    "<tbody>\n",
    "<tr class=\"odd\">\n",
    "<td align=\"right\"><img src=\"./image/Figure2.2a.png\" alt=\"\" /></td>\n",
    "<td align=\"left\"><img src=\"./image/Figure2.2b.png\"  alt=\"\" /></td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td align=\"right\"><img src=\"./image/Figure2.2c.png\" alt=\"\" /></td>\n",
    "<td align=\"left\"><img src=\"./image/Figure2.2d.png\"  alt=\"\" /></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "$ Beta(\\mu|a,b) = {{\\Gamma(a+b)} \\over {\\Gamma(a)\\Gamma(b)}} \\mu^{a-1} (1-\\mu)^{b-1}  $ 베타사전분포 식과 $ Bin(m|N,\\mu) = {n \\choose m} \\mu^{m}(1-\\mu)^{N-m}$ 이항가능도 함수를 곱하고 정규화하면 $\\mu$의 사후 분포를 구할 수 있으며 $\\mu$와 관련된 인자들만 남기면 다음 식이 나온다.  \n",
    "$$ p(\\mu | m,l,a,b) \\propto \\mu^{m+a-1}(1-\\mu)^{l+b-1} $$\n",
    "여기서 $l = N - m $이며 동전 던지기의 '뒷면'의 개수에 해당한다. 사후 분포인 위식은 사전분포와 $\\mu$에 대해 같은 함수적 종속성을 가진 것을 확인 할 수 있다. 이 것이 가능도 함수에 대해 사전 분포가 켤레적 성질을 가진 것을 반영한다. 실제로 사후분포는 단순히 또 다른 베타 분포이다. 이 새로운 베타 분포의 정규화 계수는 $ Beta(\\mu|a,b) = {{\\Gamma(a+b)} \\over {\\Gamma(a)\\Gamma(b)}} \\mu^{a-1} (1-\\mu)^{b-1}  $과의 비교르르 통해 구할 수 있으며 그 결과 다음을 얻는다.\n",
    "$$ p(\\mu | m,l,a,b) = {{\\Gamma(a+b+l+b)} \\over {\\Gamma(m+a)\\Gamma(l+b)}} \\mu^{m+a-1}(1-\\mu)^{l+b-1} $$\n",
    "x=1인 값이 m개 있고 x=0인 값 하나가 있는 관측값에서의 결과는, 사전 분포와 비교했을 때 사후분포에서는 a의 값이 m 만큼, b의 값이 l만큼 증가한 것을 확인할 수 있다. 이 사실로 사전 분포의 초매개변수 a와 b를 각각 x = 1, x = 0인 경우에 대한 **유효관찰수(Effective Number of Observations)**로 해석할 수 있다. a와 b는 반드시 정수가 아니어도 되며 만약 우리가 추가적으로 관측값을 더 얻으면 지금의 사후분포는 새로운 사전분포가 된다. 이러한 과정을 그림을 통해 보면 다음과 같다.<br>\n",
    "순차적 베이지안 추론의 한 단계를 시각화. 사전분포 a = 2, b = 2인 베타 분포로 주어질 때, $ Bin(m|N,\\mu) = {n \\choose m} \\mu^{m}(1-\\mu)^{N-m}$을 바탕으로 주어진 가능도함수는 N=m=1, 즉 x=1이라는 관측값에 해당해 새로운 사후 분포는 a=3, b=2인 분포가 됨.\n",
    "\n",
    "<table width = \"80%\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td align=\"right\"><img src=\"./image/Figure2.3a.png\" alt=\"\" /></td>\n",
    "<td align=\"center\"><img src=\"./image/Figure2.3b.png\"  alt=\"\" /></td>\n",
    "<td align=\"left\"><img src=\"./image/Figure2.3c.png\"  alt=\"\" /></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "베이지안적 관점은 학습의 **순차적(Sequential)**인 접근이 자연스러워 지며 이는 사전 분포나 가능도 함수의 선택과는 상관없이 오직 데이터가 독립적이고 동일하게 분포되었다는 것에만 의존적이다. 순차적 방법론은 관측값을 한 번에 하나씩, 혹은 한 번에 적은 수만큼 사용한다. 그리고 사용한 관측값들을 다음 관측값을 사용하기 전에 버린다. 데이터가 지속적으로 스트림되어 입력이 이루어지므로 전체 데이터를 다 확인하기 전에 예측을 시행해야하는 실시간 학습(Real-Time Learning)의 경우에 이러한 순차적 방법론 적용이 가능하다. 이는 전체 데이터 집합이 메모리에 로드되거나 저장될 필요가 없어 큰 데이터 집합을 처리하는데 적합하며, MLE 방법 역시 순차적 방법론하에서 사용가능하다.\n",
    "\n",
    "만약 우리의 목표가 다음 시도의 결과값을 가장 잘 예측하는 것이라면, 관측 데이터 집합 $ \\mathcal{D} $가 주어진 상황에서 x의 예측 분포를 계산해야 한다. 확률의 합과 곱의 법칙에 따라 이는 다음과 같다.\n",
    "$$ p(x =1 | \\mathcal{D}) = \\int_{0}^{1} p(x=1|\\mu)p(\\mu|\\mathcal{D})d\\mu = \\int_{0}^{1}\\mu p(\\mu|\\mathcal{D}) d\\mu = \\mathbb{E} \\left[ \\mu|\\mathcal{D} \\right] $$\n",
    "사후 분포 $p(\\mu|\\mathcal{D}$에 대한 결과인 식 $ p(\\mu | m,l,a,b) = {{\\Gamma(a+b+l+b)} \\over {\\Gamma(m+a)\\Gamma(l+b)}} \\mu^{m+a-1}(1-\\mu)^{l+b-1} $과 $ \\mathbb{E} \\left[ x \\right] = {{a}\\over{a+b}}  $을 이용해 다음을 구할 수 있다.\n",
    "$$ p(x=1|\\mathcal{D})= {{m+a}\\over{m+a+l+b}} $$\n",
    "위 식은 단순히 전체 관측값 중에서 x = 1인 관측값의 비율로 해석할 수 있다. 데이터 집합이 무한히 커져 $m,l \\to \\infty$ 가 된다면 위 식은 $ \\mu_{ML} = {{m}\\over{N}}$ 의 최대 공분산의 결과값과 같아진다. 베이지안의 결과값과 최대 공분산의 결과값이 무한하게 큰 데이터 집합하에서 동일한 것은 매우 일반적인 성향이다. 제한된 크기의 데이터 집합에서 $\\mu$의 사후 평균값은 사전 평균값과 $ \\mu_{ML} = {{1}\\over{N}} \\sum_{n=1}^{N}x_{n} $에서 주어진 사건의 상대적 빈도수를 바탕으로 한 최대 가능도 추정치 사이에 있다.\n",
    "\n",
    "베타분포의 그래프 그림에서 관측값의 수가 늘어날 수록 사후 분포가 더 날카롭고 뾰족하다. 이는 베타분포의 분산식 $ var \\left[ x \\right] = {{ab}\\over{(a+b)^{2}(a+b+1)}} $의 결과에서도 호가인할 수 있다. $a \\to \\infty$ 또는 $b \\to \\infty$가 됨에 다라 분산이 0에 가까워 진다. 많은 데이터를 관측하면 사후 분포의 불확실성의 정도가 꾸준하게 감소하는 것이 베이지안 학습의 일반적인 성질인지 보자.\n",
    "\n",
    "이를 위해 다시 빈도적 관점으로 살펴보면, 평균적으로 위의 성질이 실제 사실임을 알 수 있다. 관측 데이터 집합 $\\mathcal{D}$에 대해 매개변수 $\\theta$를 추정하는 일반적인 베이지안 추론을 고려하면 이를 결합분포 $p(\\theta,\\mathcal{D})$로 표현 가능하다. 매개변수 $\\theta$에 대한 기대값은 \n",
    "$$ \\mathbb{E}_{\\theta} \\left[ \\theta \\right] = \\mathbb{E}_{\\mathcal{D}} \\left[ \\mathbb{E}_{\\theta} \\left[ \\theta|\\mathcal{D} \\right]\\right] $$\n",
    "$$ \\mathbb{E}_{\\theta} \\left[ \\theta \\right] \\equiv \\int p(\\theta)\\theta d \\theta\n",
    "$$\n",
    "$$ \\mathbb{E}_{\\mathcal{D}} \\left[ \\mathbb{E}_{\\theta} \\left[ \\theta|\\mathcal{D} \\right]\\right] \\equiv \\int \\left\\{ \\int \\theta p(\\theta|\\mathcal{D})d\\theta \\right\\} p(\\mathcal{D}) d\\mathcal{D} $$\n",
    "\n",
    "이로 부터 데이터가 생성된 원 분포에 대해 평균을 낸 $\\theta$의 사후 평균값은 $\\theta$의 사전 평균과 같다는 것을 알며, 이와 유사하게 다음을 증명할 수 있다.\n",
    "$$ var_{\\theta} \\left[ \\theta \\right] = \\mathbb{E}_{\\mathcal{D}} \\left[ var_{\\theta} \\left[ \\theta|\\mathcal{D} \\right]\\right] + var_{\\mathcal{D}} \\left[ \\mathbb{E}_{\\theta} \\left[ \\theta|\\mathcal{D} \\right]\\right]$$\n",
    "위 식의 좌변은 $\\theta$의 사전 분산에 해당한다. 우변의 첫 째항은 $\\theta$의 사후 분산의 평균이며, 둘째항은 $\\theta$의 사후 평균의 분사에 해당한다. 따라서 양의 값만 갖는 이 분산에서 평균적으로 $\\theta$의 사후 분산은 사전 분산 보다 작다는 것을 알 수 있ㅇ며 분산값의 감소치는 사후평균의 분산값이 클수록 더 커진다. 이러한 추세는 평균적으로만 옳으며, 특정 관찰 집합에서는 사후분산이 사전 분산보다 클 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
